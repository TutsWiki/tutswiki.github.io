[
{
	"uri": "http://tutswiki.com/blog/",
	"title": "Blog",
	"tags": [],
	"description": "Programming articles on Tuts Wiki",
	"content": ""
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/",
	"title": "Pandas Cookbook",
	"tags": [],
	"description": "",
	"content": "Pandas Cookbook Introduction A newbie friendly introduction to Pandas with real life examples.\n"
},
{
	"uri": "http://tutswiki.com/environment-passing-in-clojure/",
	"title": "Environment Passing in Clojure",
	"tags": [],
	"description": "To fix this, we need to “pass the environment” of the calling thread to the computation thread.",
	"content": "Clojure’s vars provide a nice mechanism for managing dynamically bound state, but you need to be careful with vars when moving computations across thread boundaries. For example, suppose we implement the following timeout function:\n(import \u0026#39;(java.util.concurrent Future TimeUnit)) (defn timeout1 [millis op] (.get (future-call op) millis TimeUnit/MILLISECONDS)) The function timeout1 sends the operation op to be computed in a separate, timeout-bound thread. If the operation completes within millis milliseconds, timeout1 returns the result of that operation, otherwise it throws an exception:\n(timeout1 1000 #(inc 1)) =\u0026gt; 2 (timeout1 1000 #(Thread/sleep 2000)) ; throws java.util.concurrent.TimeoutException  This timeout implementation demonstrates the potential problem with using vars and threads:\n(def a-var 3) (binding [a-var 4] (inc a-var)) =\u0026gt; 5 (timeout1 1000 #(binding [a-var 4] (inc a-var))) =\u0026gt; 5 (binding [a-var 4] (timeout1 1000 #(inc a-var))) =\u0026gt; 4 If we rebind a-var within the timeout thread, we get the expected result of 5. But if we rebind a-var outside of the timeout thread, the computation sees the root value of 3 for a-var, not the thread-local value of 4.\nTo fix this, we need to “pass the environment” of the calling thread to the computation thread:\n(defn timeout2 [millis op] (let [env (get-thread-bindings) env-op #(with-bindings* env op)] (.get (future-call env-op) millis TimeUnit/MILLISECONDS))) (timeout2 1000 #(binding [a-var 4] (inc a-var))) =\u0026gt; 5 (binding [a-var 4] (timeout2 1000 #(inc a-var))) =\u0026gt; 5 Here we capture the environment in the context of the caller and inject it into the timeout thread using with-bindings*. Now that the timeout thread sees the same thread-local environment as the caller, the external binding of a-var works as expected.\nFinally, we can extract this pattern into a macro passing-bindings that can be used to pass an environment across thread boundaries:\n(defmacro passing-bindings [[in-env-sym] body] `(let [env# (get-thread-bindings) ~in-env-sym (fn [op#] #(with-bindings* env# op#))] ~body)) (defn timeout3 [millis op] (passing-bindings [in-env] (.get (future-call (in-env op)) millis TimeUnit/MILLISECONDS))) (binding [a-var 4] (timeout3 1000 #(inc a-var))) =\u0026gt; 5 Help improve this content Feel free to edit this pageto fix any typos or add more insights.\n  "
},
{
	"uri": "http://tutswiki.com/how-to-fix-sudo-node-command-not-found-error/",
	"title": "How to fix sudo node command not found error",
	"tags": [],
	"description": "To fix this, we need to “pass the environment” of the calling thread to the computation thread.",
	"content": "Getting permission errors when installing a module?\nAre \u0026lsquo;sudo: node: command not found\u0026rsquo; errors taking away your precious sleeping hours?\nHow to fix? You have to remove any trace of node on your system, and reinstall it. It will soothe your pain:\necho \u0026#39;export PATH=$HOME/local/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc . ~/.bashrc mkdir ~/local \u0026amp;\u0026amp; ~/node-latest-install \u0026amp;\u0026amp; ~/node-latest-install curl http://nodejs.org/dist/node-latest.tar.gz | tar xz --strip-components=1 ./configure --prefix=~/local \u0026amp;\u0026amp; make install curl https://npmjs.org/install.sh | sh rm -rf ~/node-latest-install You are one/two steps/commands away from success. Just replace /path/to/your/home/ with the absolute path to your home directory (leaving the rest of the path as is):\nsudo ln -s /path.to/your/home/local/bin/node /usr/local/bin/ sudo ln -s /path.to/your/home/local/bin/npm /usr/local/bin/ And now\u0026hellip;\nAlso see: install node and npm without having to sudo\n"
},
{
	"uri": "http://tutswiki.com/yet-another-lousy-monad-tutorial/",
	"title": "Yet another lousy monad tutorial",
	"tags": [],
	"description": "I&#39;m not a big fan of monads, but I understand them.",
	"content": "  If a function has type A → B, and another function has type B → C, then we can \u0026ldquo;compose\u0026rdquo; them into a new function of type A → C.\n  Let\u0026rsquo;s talk about functions that can return multiple values. We can model these as functions of type A → List\u0026lt;B\u0026gt;. There is a natural way to \u0026ldquo;compose\u0026rdquo; two such functions. If one function has type A → List\u0026lt;B\u0026gt;, and another function has type B → List\u0026lt;C\u0026gt;, then we can \u0026ldquo;compose\u0026rdquo; them into a new function of type A → List\u0026lt;C\u0026gt;. The \u0026ldquo;composition\u0026rdquo; works by joining together all the intermediate lists of values into one. This is similar to MapReduce, which also collects together lists of results returned by individual workers.\n  Let\u0026rsquo;s talk about functions that either return a value, or fail somewhere along the way. We can model these as functions of type A → Option\u0026lt;B\u0026gt;, where Option\u0026lt;B\u0026gt; is a type that contains either a value of type B, or a special value None. There is a natural way to \u0026ldquo;compose\u0026rdquo; two such functions. If one function has type A → Option\u0026lt;B\u0026gt;, and another function has type B → Option\u0026lt;C\u0026gt;, then we can \u0026ldquo;compose\u0026rdquo; them into a new function of type A → Option\u0026lt;C\u0026gt;. The \u0026ldquo;composition\u0026rdquo; works just like regular function composition, except if the first function returns None, then it gets passed along and the second function doesn\u0026rsquo;t get called. This way you can have a \u0026ldquo;happy path\u0026rdquo; in your code, and check for None only at the end.\n  Let\u0026rsquo;s talk about functions that call a remote machine asynchronously. We can model these as functions of type A → Promise\u0026lt;B\u0026gt;, where Promise\u0026lt;B\u0026gt; is a type that will eventually contain a value of type B, which you can wait for. There is a natural way to \u0026ldquo;compose\u0026rdquo; two such functions. If one function has type A → Promise\u0026lt;B\u0026gt;, and another function has type B → Promise\u0026lt;C\u0026gt;, then we can \u0026ldquo;compose\u0026rdquo; them into a new function of type A → Promise\u0026lt;C\u0026gt;. The \u0026ldquo;composition\u0026rdquo; is an asynchronous operation that waits for the first promise to return a value, then calls the second function on that value. This is known in some languages as \u0026ldquo;promise pipelining\u0026rdquo;. It can sometimes make remote calls faster, because you can send both calls to the remote machine in the same request.\n  Let\u0026rsquo;s talk about functions that do input or output in a pure functional language, like Haskell. We can define IO\u0026lt;A\u0026gt; as the type of opaque \u0026ldquo;IO instructions\u0026rdquo; that describe how to do some IO and return a value of type A. These \u0026ldquo;instructions\u0026rdquo; might eventually be executed by the runtime, but can also be freely passed around and manipulated before that. For example, to create instructions for reading a String from standard input, we\u0026rsquo;d have a function of type Void → IO\u0026lt;String\u0026gt;, and to create instructions for writing a String to standard output, we\u0026rsquo;d have String → IO\u0026lt;Void\u0026gt;. There is a natural way to \u0026ldquo;compose\u0026rdquo; two such functions. If one function has type A → IO\u0026lt;B\u0026gt;, and another function has type B → IO\u0026lt;C\u0026gt;, then we can \u0026ldquo;compose\u0026rdquo; them into a new function of type A → IO\u0026lt;C\u0026gt;. The \u0026ldquo;composition\u0026rdquo; works by just doing the IO in sequence. Eventually the whole program returns one huge complicated IO instruction with explicit sequencing inside, which is then passed to the runtime for execution. That\u0026rsquo;s how Haskell works.\n  Another thing to note is that each of the examples above also has a natural \u0026ldquo;identity\u0026rdquo; function, such that \u0026ldquo;composing\u0026rdquo; it with any other function F gives you F again. For ordinary function composition, it\u0026rsquo;s the ordinary identity function A → A. For lists, it\u0026rsquo;s the function A → List\u0026lt;A\u0026gt; that creates a single-element list. For options, it\u0026rsquo;s the function A → Option\u0026lt;A\u0026gt; that takes a value and returns an option containing that value. For promises, it\u0026rsquo;s the function A → Promise\u0026lt;A\u0026gt; that takes a value and makes an immediately fulfilled promise out of it. And for IO, it\u0026rsquo;s the function A → IO\u0026lt;A\u0026gt; that doesn\u0026rsquo;t actually do any IO.\nAt this point we could go all mathematical and talk about how \u0026ldquo;compose\u0026rdquo; is like number multiplication, and \u0026ldquo;identity\u0026rdquo; is like the number 1, and then go off into monoids and categories and functors and other things that are frankly boring to me. So let\u0026rsquo;s not go there! Whew!\nInstead, to stay more on the programming track, let\u0026rsquo;s use a Java-like syntax to define an interface Monadwith two methods \u0026ldquo;identity\u0026rdquo; and \u0026ldquo;compose\u0026rdquo;. The five examples above will correspond to five different concrete classes that implement that interface, for different choices of the type parameter T.\nThe main complication is that the type parameter T must not be a simple type, like String. Instead it must be itself a generic type, like List, Option or Promise. The reason is that we want to have a single implementation of Monad\u0026lt;Option\u0026gt;, not separate implementations like Monad\u0026lt;Option\u0026lt;Integer\u0026gt;\u0026gt;, Monad\u0026lt;Option\u0026lt;String\u0026gt;\u0026gt; and so on. Java and C# don\u0026rsquo;t support generic types whose parameters are themselves generic types (the technical term is \u0026ldquo;higher-kinded types\u0026rdquo;), but C++ has some support for them, called \u0026ldquo;template template parameters\u0026rdquo;. Some functional languages have higher-kinded types, like Haskell, while others don\u0026rsquo;t have them, like ML.\nAnyway, here\u0026rsquo;s what it would look like in Java, if Java supported such things:\ninterface Monad\u0026lt;T\u0026gt; { \u0026lt;A\u0026gt; Function\u0026lt;A, T\u0026lt;A\u0026gt;\u0026gt; identity(); \u0026lt;A, B, C\u0026gt; Function\u0026lt;A, T\u0026lt;C\u0026gt;\u0026gt; compose( Function\u0026lt;A, T\u0026lt;B\u0026gt;\u0026gt; first, Function\u0026lt;B, T\u0026lt;C\u0026gt;\u0026gt; second ); } class OptionMonad implements Monad\u0026lt;Option\u0026gt; { public \u0026lt;A\u0026gt; Function\u0026lt;A, Option\u0026lt;A\u0026gt;\u0026gt; identity() { // Implementation omitted, figure it out  } public \u0026lt;A, B, C\u0026gt; Function\u0026lt;A, Option\u0026lt;C\u0026gt;\u0026gt; compose( Function\u0026lt;A, Option\u0026lt;B\u0026gt;\u0026gt; first, Function\u0026lt;B, Option\u0026lt;C\u0026gt;\u0026gt; second ) { // Implementation omitted, do it yourself  } } Defining Monad as an interface allows us to implement some general functionality that will work on all monads. For example, there\u0026rsquo;s a well known function \u0026ldquo;liftM\u0026rdquo; that converts a function of type A → B into a function of type List\u0026lt;A\u0026gt; → List\u0026lt;B\u0026gt;, or Promise\u0026lt;A\u0026gt; → Promise\u0026lt;B\u0026gt;, or anything else along these lines. For different monads, liftM will do different useful things, e.g. liftM on lists is just the familiar \u0026ldquo;map\u0026rdquo; function in disguise. The implementation of liftM with lambda expressions would be very short, though a little abstract:\n\u0026lt;T, A, B\u0026gt; Function\u0026lt;T\u0026lt;A\u0026gt;, T\u0026lt;B\u0026gt;\u0026gt; liftM( Function\u0026lt;A, B\u0026gt; func, Monad\u0026lt;T\u0026gt; monad ) { return (T\u0026lt;A\u0026gt; ta) -\u0026gt; monad.compose( () -\u0026gt; ta, (A a) -\u0026gt; monad.identity().apply(func.apply(a)) ).apply(void); } Or if you don\u0026rsquo;t like lambda expressions, here\u0026rsquo;s a version without them:\n\u0026lt;T, A, B\u0026gt; Function\u0026lt;T\u0026lt;A\u0026gt;, T\u0026lt;B\u0026gt;\u0026gt; liftM( Function\u0026lt;A, B\u0026gt; func, Monad\u0026lt;T\u0026gt; monad ) { return new Function\u0026lt;T\u0026lt;A\u0026gt;, T\u0026lt;B\u0026gt;\u0026gt;() { public T\u0026lt;B\u0026gt; apply (T\u0026lt;A\u0026gt; ta) { return monad.compose( new Function\u0026lt;Void, T\u0026lt;A\u0026gt;\u0026gt;() { public T\u0026lt;A\u0026gt; apply() { return ta; } }, new Function\u0026lt;A, T\u0026lt;B\u0026gt;\u0026gt;() { public T\u0026lt;B\u0026gt; apply(A a) { return monad.identity().apply(func.apply(a)); } } ).apply(void); } } } Monads first became popular as a nice way to deal with IO instructions in a pure language, treating them as first-class values that can be passed around, like in my example 5. Imperative languages don\u0026rsquo;t need monads for IO, but they often face a similar problem of \u0026ldquo;option chaining\u0026rdquo; or \u0026ldquo;error chaining\u0026rdquo;, like in my example 3. For example, the option types in Rust or Swift would benefit from having a \u0026ldquo;happy path\u0026rdquo; through the code and a centralized place to handle errors, which is exactly the thing that monads would give you.\nSome people think that monads are about side effects, like some sort of escape hatch for Haskell. That\u0026rsquo;s wrong, because you could always do IO without monads, and in fact the first version of Haskell didn\u0026rsquo;t use them. In any case, only two of my five examples involve side effects. Monads are more like a design pattern for composing functions, which shows up in many places. I think the jury is still out on whether imperative/OO languages need to use monads explicitly, but it might be useful to notice them when they appear in your code implicitly.\nHelp improve this content Feel free to edit this pageto fix any typos or add more insights.\n"
},
{
	"uri": "http://tutswiki.com/ruby-enumerable/",
	"title": "A Deeper Look at Ruby&#39;s Enumerable",
	"tags": [],
	"description": "Ruby’s Enumerable module gives you a way of iterating over collections in a lazy manner, loading only what you need, when you need it. But it gives us so much more than that.",
	"content": "Have you ever needed to load a VERY large file in ruby? No I don’t mean your 500 line rails model. I mean a several gig binary or text file.\nTry it. Watch your machine become unresponsive. Cry a little inside. Then reach for enumerable.\nRuby’s Enumerable module gives you a way of iterating over collections in a lazy manner, loading only what you need, when you need it. But it gives us so much more than that.\nToday I am going to walk you through a couple of highly useful methods from Enumerable that has come up in a few coding challenges I have done over the years.\neach_cons, any?, all?, none? I use these methods when I need to determine the \u0026lsquo;distance or difference\u0026rsquo; in a set of numbers or objects. each_cons simply gives us a \u0026lsquo;sliding\u0026rsquo; window of our list so we can compare multiple items in our list.\nnumbers = [1,3,5,8,10,54,99] cards = [5,3,4,6,2] # get only the values where the distance is greater than 10 numbers.each_cons(2).select {|a,b| b-a\u0026gt;10 } #=\u0026gt; [[10, 54], [54, 99]] # determine if the hand is a straight cards.sort.each_cons(5).all? do |series| (series.first..series.last).to_a == series end #=\u0026gt; true Our first example shows how to get the elements in the numbers list that are over 10 units in difference. I do this by using each_cons to give me a sliding window of 2 elements at a time. This give me:\nAt each step on the way I check b-a and see if that is greater than 10. If so, the select will return those groups of elements.\nThe second example simply sorts a set of \u0026lsquo;cards\u0026rsquo; and then looking at all 5 cards through each_cons and comparing the scores to see if they are in order and in sequence (a+1==b).\nLet’s play off this example a bit more, this time with dice. If we have to implement small and large straights, we have a similar problem, with a similar solution:\nFor the small straight we get 2 windows, becuase there are 5 values in the list and we are calling each_cons(4). Therefore we want a postfix of any? because either of the windows can be a run of 4.\nIn the second example we use all? to be more explicit, yet any? would have worked as well, because in the large straight, we only have one sliding window, 2,3,4,5,6.\nany? all? none? These have to be a few of my favorite methods in enumerable.\nGiven no args, they take a list of bool values and returns a bool. So [true, true, false].all? #=\u0026gt; false.\nKinda useful, but not really. If we pass it a block of code however.. now we can do something useful. Consider this example:\n.any? and .none? do what you probably think. Where .all? only returns true if ALL the conditions and elements match up, .any? returns true if ANY of them match, and .none? returns true if there were NO matches.\nWeird things like look-ahead? Say you have a file to read in line by line. You need to compare the current line to the next line to look for duplicates. each_cons(2) to the rescue!\nThis will tell us of the current line and the following line are the same.\n More uses for each_cons averages distances smoothing plots graphing geometry  Help improve this content Feel free to edit this pageto fix any typos or add more insights.\n"
},
{
	"uri": "http://tutswiki.com/rest-api-in-clojure/",
	"title": "A REST API in Clojure",
	"tags": [],
	"description": "A newbie friendly introduction to REST API in Clojure.",
	"content": "Clojure is one of the most interesting new languages targeting the JVM. Initially only the JVM, in the meantime it is also available for JavaScript. Essentially, you can write Clojure and either execute it as Java program or JavaScript program, of course each flavor has its unique features as well.\nClojure is a Lisp, thus the syntax may be foreign, but it is really, really easy since there are very few syntactic variations. The language “Lisp” is very lean and usually easily learned.\nIn this post, we’re going to create a complete REST application from scratch. There are already some (very) good tutorials available, but some are not quite up to date (see Heroku’s Devcenter or Mark McGranaghan for good ones). Clojure itself is still a young language, Lisp of course has a lot of history.\nOur application should allow creating, listing, fetching, updating, and deleting of documents.\nA document looks like this (JSON encoded):\n{ \u0026#34;id\u0026#34; : \u0026#34;some id\u0026#34;, \u0026#34;title\u0026#34; : \u0026#34;some title\u0026#34; \u0026#34;text\u0026#34; : \u0026#34;some text\u0026#34; }  A GET call to /documents should return a list of these documents. A POST call to /documents with a documents as body shall create a new document, assigning a new id (ignoreing the posted one). A GET to /documents/[ID] should return the document with the given id, or 404 if the document does not exist. A PUT to /documents/[ID] should update the document with the given id and replace title and text with those from the document in the uploaded body. A DELETE to /documents/[ID] should delete the document with the given id and return 204 (NO CONTENT) in any case.  Creating the project scaffolding We’re going to use Leiningen, the defacto build system and dependency manager for Clojure projects. Download and install it, then execute:\nlein new compojure clojure-rest We’re creating a new Compojureproject called clojure-rest. Compojure is the library that maps URLs to functions in our program. Compojure (and our project) builds on Ring is the basic Server API. To start the new project run:\nlein ring server This starts the server on localhost:3000 and automatically restarts the server if any of the project files change. Thus, you can leave it running while we develop our application.\nThe new command generates two very important files for us:\nproject.clj is the project configuration. It states dependencies, the entry point etc. (read the whole documentation on Leiningen.org, and src/clojure_rest/handler.clj which contains a starting point for our application.\nProject configuration (project.clj) (defproject clojure-rest \u0026#34;0.1.0-SNAPSHOT\u0026#34; :description \u0026#34;FIXME: write description\u0026#34; :url \u0026#34;http://example.com/FIXME\u0026#34; :dependencies [[org.clojure/clojure \u0026#34;1.4.0\u0026#34;] [compojure \u0026#34;1.1.1\u0026#34;]] :plugins [[lein-ring \u0026#34;0.7.3\u0026#34;]] :ring {:handler clojure-rest.handler/app} :profiles {:dev {:dependencies [[ring-mock \u0026#34;0.1.3\u0026#34;]]}}) Update the file to look like this: (defproject clojure-rest \u0026#34;0.1.0-SNAPSHOT\u0026#34; :description \u0026#34;REST service for documents\u0026#34; :url \u0026#34;https://tutswiki.com\u0026#34; :dependencies [[org.clojure/clojure \u0026#34;1.4.0\u0026#34;] [compojure \u0026#34;1.1.1\u0026#34;] [ring/ring-json \u0026#34;0.1.2\u0026#34;] [c3p0/c3p0 \u0026#34;0.9.1.2\u0026#34;] [org.clojure/java.jdbc \u0026#34;0.2.3\u0026#34;] [com.h2database/h2 \u0026#34;1.3.168\u0026#34;] [cheshire \u0026#34;4.0.3\u0026#34;]] :plugins [[lein-ring \u0026#34;0.7.3\u0026#34;]] :ring {:handler clojure-rest.handler/app} :profiles {:dev {:dependencies [[ring-mock \u0026#34;0.1.3\u0026#34;]]}}) Besides the JSON parsing library Cheshire, we added the C3P0 Connection Pool, the H2 DatabaseJDBC driver and Clojure’s java.jdbccontrib-library.\nI also updated the :url and :description fields.\nThe request handler (handler.clj) Next let’s have a look at the generated request handler src/clojure_rest/handler.clj:\n(ns clojure-rest.handler (:use compojure.core) (:require [compojure.handler :as handler] [compojure.route :as route])) (defroutes app-routes (GET \u0026#34;/\u0026#34; [] \u0026#34;Hello World\u0026#34;) (route/not-found \u0026#34;Not Found\u0026#34;)) (def app (handler/site app-routes)) The route GET \u0026quot;/\u0026quot; [] \u0026quot;Hello World\u0026quot; is responsible for our result we saw in the browser. It maps all GET requests to / without parameters to \u0026ldquo;Hello World\u0026rdquo;. The (def app (handler/site app-routes)) part configures our application (registering the routes).\nOur first step is to update the configuration. We’re going to work with JSON, so let’s include some Ring middlewares to setup response headers (wrap-json-response) and parse request bodies (wrap-json-body) for us. A middleware is just a wrapper around a handler, thus it can pre- and post-process the whole request/response cycle.\n(def app (-\u0026gt; (handler/api app-routes) (middleware/wrap-json-body) (middleware/wrap-json-response))) We switched also from the handler/site template to handler/api which is more appropriate for REST APIs (documentation).\nNext let’s define the routes for our application:\n(defroutes app-routes (context \u0026#34;/documents\u0026#34; [] (defroutes documents-routes (GET \u0026#34;/\u0026#34; [] (get-all-documents)) (POST \u0026#34;/\u0026#34; {body :body} (create-new-document body)) (context \u0026#34;/:id\u0026#34; [id] (defroutes document-routes (GET \u0026#34;/\u0026#34; [] (get-document id)) (PUT \u0026#34;/\u0026#34; {body :body} (update-document id body)) (DELETE \u0026#34;/\u0026#34; [] (delete-document id)))))) (route/not-found \u0026#34;Not Found\u0026#34;)) We define GET and POST for the context \u0026ldquo;/documents, and GET, PUT, DELETE for the context \u0026ldquo;:id\u0026rdquo; on top of that. :id is a placeholder and can then be injected into our parameter vector. The POST and PUT request have a special parameter body for the parsed body (this parameter is provided by the wrap-json-body middleware. For more on routes, take a look at Compojure’s documentation.\nBefore we define the functions to carry out the requests, let’s fix the imports and open a pool of database connections to work with.\nThe namespace declaration is used to define which namespaces shall be made available by Clojure.\n(ns clojure-rest.handler (:import com.mchange.v2.c3p0.ComboPooledDataSource) (:use compojure.core) (:use cheshire.core) (:use ring.util.response) (:require [compojure.handler :as handler] [ring.middleware.json :as middleware] [clojure.java.jdbc :as sql] [compojure.route :as route])) We import C3P0’s ComboPooledDataSource, a plain Java class. Next, we fetch the functions defined in compojure.core, cheshire.core, and ring.util.response into our namespace, they can be used without qualifying. Finally we require some more libraries, this time with a qualifier to prevent name clashes or to support nicer separation. I’m not sure when to make the cut between :use and :require yet, so the cut is abitrary.\n(def db-config {:classname \u0026#34;org.h2.Driver\u0026#34; :subprotocol \u0026#34;h2\u0026#34; :subname \u0026#34;mem:documents\u0026#34; :user \u0026#34;\u0026#34; :password \u0026#34;\u0026#34;}) Note, we use a in-memory database. If you’d like to keep your database between restarts, you could use :subname \u0026quot;/tmp/documents\u0026quot; for example.\nNext we open a pool of connections. C3P0 has no Clojure wrapper, so we deal with Java classes and objects directly (hence a bit more code).\n(defn pool [config] (let [cpds (doto (ComboPooledDataSource.) (.setDriverClass (:classname config)) (.setJdbcUrl (str \u0026#34;jdbc:\u0026#34; (:subprotocol config) \u0026#34;:\u0026#34; (:subname config))) (.setUser (:user config)) (.setPassword (:password config)) (.setMaxPoolSize 6) (.setMinPoolSize 1) (.setInitialPoolSize 1))] {:datasource cpds})) (def pooled-db (delay (pool db-config))) (defn db-connection [] @pooled-db) Since we deal with a in-memory database, we need to create our table now.\n(sql/with-connection (db-connection) (sql/create-table :documents [:id \u0026#34;varchar(256)\u0026#34; \u0026#34;primary key\u0026#34;] [:title \u0026#34;varchar(1024)\u0026#34;] [:text :varchar])) The intent should be easy to understand, for the details take a look at the java.jdbc documentation. We create a table documents with a :id, :title, and :text column. Note that the database column is called id, not :id.\nThe only thing missing are the functions to actually perform the actions requested by our clients.\nTo return a single document with a given id, we could come up with this:\n(defn get-document [id] (sql/with-connection (db-connection) (sql/with-query-results results [\u0026#34;select * from documents where id = ?\u0026#34; id] (cond (empty? results) {:status 404} :else (response (first results)))))) It reads like this: when called with an id, open a database connection, perform select * from documents where id = ? with the given id as parameter. If the result is empty, return 404, otherwise return the first (and only) document as response.\nThe response call will convert the document into JSON, this functionality is provided by wrap-json-response, which also sets the correct Content-Type etc.\nAnother nice one is the creation of new documents:\n(defn uuid [] (str (java.util.UUID/randomUUID))) (defn create-new-document [doc] (let [id (uuid)] (sql/with-connection (db-connection) (let [document (assoc doc \u0026#34;id\u0026#34; id)] (sql/insert-record :documents document))) (get-document id))) Here we use Java’s UUID generator (without import, hence the full package name) to generate a new id for each document created. The second let statement is responsible to replace the user-provided id (if any) with our generated one. Remember that Clojure’s datastructures are immutable, so we need to use the document variable thereafter, instead of the doc which still contains the old (or no) id.\nReturning the document is delegated to the get-document function.\nThe complete handler.clj To round the post up, here is the whole program:\n(ns clojure-rest.handler (:import com.mchange.v2.c3p0.ComboPooledDataSource) (:use compojure.core) (:use cheshire.core) (:use ring.util.response) (:require [compojure.handler :as handler] [ring.middleware.json :as middleware] [clojure.java.jdbc :as sql] [compojure.route :as route])) (def db-config {:classname \u0026#34;org.h2.Driver\u0026#34; :subprotocol \u0026#34;h2\u0026#34; :subname \u0026#34;mem:documents\u0026#34; :user \u0026#34;\u0026#34; :password \u0026#34;\u0026#34;}) (defn pool [config] (let [cpds (doto (ComboPooledDataSource.) (.setDriverClass (:classname config)) (.setJdbcUrl (str \u0026#34;jdbc:\u0026#34; (:subprotocol config) \u0026#34;:\u0026#34; (:subname config))) (.setUser (:user config)) (.setPassword (:password config)) (.setMaxPoolSize 1) (.setMinPoolSize 1) (.setInitialPoolSize 1))] {:datasource cpds})) (def pooled-db (delay (pool db-config))) (defn db-connection [] @pooled-db) (sql/with-connection (db-connection) ; (sql/drop-table :documents) ; no need to do that for in-memory databases (sql/create-table :documents [:id \u0026#34;varchar(256)\u0026#34; \u0026#34;primary key\u0026#34;] [:title \u0026#34;varchar(1024)\u0026#34;] [:text :varchar])) (defn uuid [] (str (java.util.UUID/randomUUID))) (defn get-all-documents [] (response (sql/with-connection (db-connection) (sql/with-query-results results [\u0026#34;select * from documents\u0026#34;] (into [] results))))) (defn get-document [id] (sql/with-connection (db-connection) (sql/with-query-results results [\u0026#34;select * from documents where id = ?\u0026#34; id] (cond (empty? results) {:status 404} :else (response (first results)))))) (defn create-new-document [doc] (let [id (uuid)] (sql/with-connection (db-connection) (let [document (assoc doc \u0026#34;id\u0026#34; id)] (sql/insert-record :documents document))) (get-document id))) (defn update-document [id doc] (sql/with-connection (db-connection) (let [document (assoc doc \u0026#34;id\u0026#34; id)] (sql/update-values :documents [\u0026#34;id=?\u0026#34; id] document))) (get-document id)) (defn delete-document [id] (sql/with-connection (db-connection) (sql/delete-rows :documents [\u0026#34;id=?\u0026#34; id])) {:status 204}) (defroutes app-routes (context \u0026#34;/documents\u0026#34; [] (defroutes documents-routes (GET \u0026#34;/\u0026#34; [] (get-all-documents)) (POST \u0026#34;/\u0026#34; {body :body} (create-new-document body)) (context \u0026#34;/:id\u0026#34; [id] (defroutes document-routes (GET \u0026#34;/\u0026#34; [] (get-document id)) (PUT \u0026#34;/\u0026#34; {body :body} (update-document id body)) (DELETE \u0026#34;/\u0026#34; [] (delete-document id)))))) (route/not-found \u0026#34;Not Found\u0026#34;)) (def app (-\u0026gt; (handler/api app-routes) (middleware/wrap-json-body) (middleware/wrap-json-response))) Yeah, the whole program with connection pooling, JSON de/encoding in roughly 90 lines of (admittedly dense) code.\nTo sum it up: Clojure is fun, concise, and very powerful. Together with the excellent Java integration it ranks very high on my “languages I adore” list.\nHelp improve this content Feel free to edit this pageto fix any typos or add more insights.\n  "
},
{
	"uri": "http://tutswiki.com/abstract-classes-and-interfaces-in-python/",
	"title": "Abstract classes and interfaces in Python",
	"tags": [],
	"description": "Abstract classes, methods and Zope interfaces, adapters in Python",
	"content": "Abstract base classes and interfaces are entities that are similar in purpose and meaning. Both the first and second are a peculiar way of documenting the code and help to limit (decouple) the interaction of individual abstractions in the program (classes).\nPython is a very flexible language. One facet of this flexibility is the possibilities provided by metaprogramming. And although abstract classes and interfaces are not represented in the core of the language, the former were implemented in the standard abc module, and the latter in the Zope project (the zope.interfaces module).\nIt makes no sense to use both at the same time, and therefore each programmer must determine for himself which tool to use when designing applications.\nAbstract base classes (abc) Starting from version 2.6 of the language, the abc module is included in the standard library, which adds abstract base classes (hereinafter ABC) to the language.\nABC allows you to define a class, indicating which methods or properties must be overridden in inherited classes:\nfrom abc import ABCMeta, abstractmethod, abstractproperty class Movable(): __metaclass __ = ABCMeta @abstractmethod def move(): \u0026#34;\u0026#34;\u0026#34;Move object\u0026#34;\u0026#34;\u0026#34; @abstractproperty def speed(): \u0026#34;\u0026#34;\u0026#34;Object speed\u0026#34;\u0026#34;\u0026#34; Thus, if we want to use an object with the ability to move and a certain speed in the code, then we should use the Movable class as one of the base classes.\nThe presence of the necessary methods and attributes of the object is now guaranteed by the presence of abstractmethod and abstractproperty.\nclass Car(Movable): def __init__: self.speed = 10 self.x = 0 def move(self): self.c += self.speed def speed(self): return self.speed assert issubclass (Car, Movable) assert ininstance (Car(), Movable) It can be seen that the concept of ABC fits well into the class inheritance hierarchy, it is easy to use them, and the implementation, if you look into the source code of the abc module, is very simple. Abstract classes are used in the standard collections and number modules, defining the methods of custom inherited classes necessary for definition.\nDetails and considerations for using ABC can be found in PEP-3119.\nInterfaces (zope.interfaces) The Zope Toolkit (ZTK) is a set of libraries intended for reuse by projects to develop web applications or web frameworks. It is developed by the contributors of the Zope Foundation. The zope framework has evolved into a set of almost independent components. The glue that holds the components together is the interfaces and the adapters based on them.\nThe zope.interfaces module is the result of this work.\nIn the simplest case, using interfaces is similar to ABC:\nimport zope.interface class IVehicle(zope.interface.Interface): \u0026#34;\u0026#34;\u0026#34;Any moving thing\u0026#34;\u0026#34;\u0026#34; speed = zope.interface.Attribute(\u0026#34;\u0026#34;\u0026#34;Movement speed\u0026#34;\u0026#34;\u0026#34;) def move(): \u0026#34;\u0026#34;\u0026#34;Make a single step\u0026#34;\u0026#34;\u0026#34; class Car(object): zope.interface.implements (IVehicle) def __init__: self.speed = 1 self.location = 1 def move (self): self.location = self.speed * 1 print(\u0026#34;moved!\u0026#34;) assert IVehicle.implementedBy (Car) assert IVehicle.providedBy (Car ()) The interface declaratively shows what attributes and methods the object should have. Moreover, the class implements the interface, and the object of the class provides. You should pay attention to the difference between these concepts!\n\u0026ldquo;Implementing\u0026rdquo; an interface means that only the \u0026ldquo;produced\u0026rdquo; entity will have the required properties; and \u0026ldquo;providing\u0026rdquo; an interface speaks of the specific capabilities of the entity being evaluated. Accordingly, in Python, classes, by the way, can both implement and provide an interface.\nIn fact, the implementation declaration (IVehicle) is a convention; just a promise that a given class and its objects behave that way. No real checks will be made.\nclass IVehicle (zope.interface.Interface): \u0026#34;\u0026#34;\u0026#34;Any moving thing\u0026#34;\u0026#34;\u0026#34; speed = zope.interface.Attribute(\u0026#34;\u0026#34;\u0026#34;Movement speed\u0026#34;\u0026#34;\u0026#34;) def move(): \u0026#34;\u0026#34;\u0026#34;Make a single step\u0026#34;\u0026#34;\u0026#34; class Car(object): zope.interface.implements(IVehicle) assert IVehicle.implementedBy(Car) assert IVehicle.providedBy(Car()) The component architecture of Zope includes another important concept - adapters. Generally speaking, this is a simple design pattern that corrects one class for use somewhere where a different set of methods and attributes is required.\nAdapters Consider a simple an example from the Comprehensive Guide to Zope Component Architecture.\nSuppose there are a couple of classes, Guest and Desk. Let\u0026rsquo;s define interfaces to them, plus a class that implements the Guest interface:\nimport zope.interface from zope.interface import implements from zope.component import adapts, getGlobalSiteManager class IDesk(zope.interface.Interface): def register(): \u0026#34;Register a person\u0026#34; class IGuest(zope.interface.Interface): name = zope.interface.Attribute (\u0026#34;\u0026#34;\u0026#34;Person`s name\u0026#34;\u0026#34;\u0026#34;) class Guest (object): implements(IGuest) def __init __ (self, name): self.name = name The adapter must account for the anonymous guest by registering in the list of names:\nclass GuestToDeskAdapter (object): adapts(IGuest) implements(IDesk) def __init __ (self, guest): self.guest = guest def register (self): guest_name_db.append (self.guest.name) There is a registry that keeps track of adapters by interface. Thanks to it, you can get an adapter by passing an adaptable object to the call of the interface class. If the adapter is not registered, the second argument to the interface will be returned:\nguest = Guest (\u0026#34;Ivan\u0026#34;) adapter = IDesk (guest, alternate = None) print adapter \u0026gt;\u0026gt;\u0026gt;\u0026gt; None found gsm = getGlobalSiteManager () gsm.registerAdapter (GuestToDeskAdapter) adapter = IDesk (guest, alternate = \u0026#34;None found\u0026#34;) print adapter \u0026gt;\u0026gt;\u0026gt;\u0026gt; __ main __. GuestToDeskAdapter object at 0xb7beb64c\u0026gt; This infrastructure is useful for splitting code into components and linking them together.\nOne of the most striking examples of using this approach besides Zope itself is the Twisted network framework, where a fair amount of the architecture relies on zope.interfaces interfaces.\nConclusion Upon closer inspection, it turns out that interfaces and abstract base classes are two different things.\nAbstract classes basically hardcode the required front-end part. Checking an object against the interface of an abstract class is checked using the built-in isinstance function; class - issubclass. An abstract base class should be included in the hierarchy as a base class or mixin.\nThe downside is the semantics of checks issubclass, isinstance, which intersect with ordinary classes (their inheritance hierarchy). No additional abstractions are built on the ABC.\nInterfaces are a declarative entity, they do not set any boundaries; simply asserts that the class implements and its object provides the interface. Semantically, the statements implementedBy, providedBy are more correct. On such a simple basis, it is convenient to build a component architecture using adapters and other derived entities, which is what the large Zope and Twisted frameworks do.\nIt should be understood that the use of both tools makes sense only when building and using relatively large OOP systems - frameworks and libraries, in small programs they can only confuse and complicate the code with unnecessary abstractions.\nHelp improve this content Please fix any typos or add more insights by editing this page.\n"
},
{
	"uri": "http://tutswiki.com/deep-learning-cardiovascular-imaging/",
	"title": "How Deep Learning Helped Reducing Variability in Cardiovascular Imaging",
	"tags": [],
	"description": "New software based on deep learning algorithms automatically and accurately calculates LVEF",
	"content": "Bay Labs, a San Francisco-based medical technology company which focuses on using artificial intelligence to improve cardiovascular imaging, has released a new software EchoMD AutoEF. It is being claimed that this software will help to reduce the variability in cardiovascular imaging.\nThe software uses deep learning techniques to accurately calculate the left ventricular ejection fraction.\nWhat is Ejection Fraction? During each pumping cycle of our heart, it contracts and relaxes. When it contracts it passes the blood to ventricles. Ventricles are basically the pumping chambers. Ejection Fraction is the amount of blood withdrawn from the heart when it contracts. Medical professionals use EF to identify the health of a heart. They generally measure the EF from left ventricle because it is the main pumping chamber of the heart which passes the oxygenated blood through the ascending (upward) aorta to the rest of the body.\nMeasuring EF There are various methods available to measure LVEF, out of which Simpson’s biplane method is used widely. This method has about 9.2% average variability. The EchoMD AutoEF software by Bay Labs has an average variability of 8.2%. Moreover, EchoMD AutoEF doesn\u0026rsquo;t require any user intervention, it\u0026rsquo;s fully automatic. It calculates LVEF from complete echocardiographic patient studies, automatically.\nHow Deep Learning Helped? At present Human intervention is required to calculate LVEF. Medical professionals have to go through the recorded clips. They watch them carefully and pick the best ones then they manipulate them for quantification. This is a very time consuming and prone-to-error process (as it is done by humans). The deep learning algorithms helped in this case by totally eliminating the need to do all of the above manually. The training set included 4,000,000 images from about 9,000 patients.\nQuoting Richard Bae, who is the Director of the Echocardiography Laboratory at the Minneapolis Heart Institute:\n \u0026ldquo;Historically there have been challenges with variability and reproducibility in reporting of the ejection fraction, especially when the EF is not normal; our study showed that the EchoMD AutoEF algorithms can aid interpretation enormously and have less variability than cardiologists reported in the literature.”\n  \u0026ldquo;By supporting fast, efficient and accurate AI-assisted echocardiogram analysis, the algorithms can allow physicians to focus on putting results into the context for the patient - guiding prognosis and course of management.”\n This is a great innovation in the medical field. It will help cardiologists in better decision making.\n"
},
{
	"uri": "http://tutswiki.com/google-engineers-boycott-security-tool-military/",
	"title": "Google Engineers Boycott Against Security Tool for Military",
	"tags": [],
	"description": "A group of 9 cloud engineers at Google has refused to work on air-gap due to which Google may lose a deal worth $10 billion.",
	"content": "On the one hand this is good as it shows that employees get ample space to air grievances, but on the other hand, the shareholders will get angry as it hampers Google\u0026rsquo;s ability to compete. In order to get government contracts especially those which involves sensitive data and military require some certifications, which Google\u0026rsquo;s competitors like Microsoft and Amazon have but Google doesn\u0026rsquo;t. This air-gap feature was supposed to help Google with that but it seems it\u0026rsquo;ll be abandoned.\nWhat is air-gap? Microsoft and Amazon have set-up a service called Government Cloud (Azure Government and AWS GovCloud) where the sensitive government information can be stored. An important feature of this service is air-gap. It is a security measure which ensures that a secured computer network is physically isolated from unsecured networks. Therefore, instead of storing data from multiple sources in a single server/system you store it in a separate isolated hardware. This is helpful for the government if they want to know where their data reside (physically) so that they can wipe it immediately.\nAlthough the feature is not that difficult to implement, Google can form a new team to work on it but looking at the fate of Project Maven which got similar boycott, it\u0026rsquo;d be difficult for Google.\nBesides, U.S. Congress is accusing Google over the partnership with Huawei, a Chinese manufacturer which makes Android phones. They said  You were not with the Pentagon on an AI project but you\u0026rsquo;ll work with the Chinese handset manufacturer.\n That is a very difficult situation for Google and I think they are right now working on how to handle this.\nSource: Bloomberg\n"
},
{
	"uri": "http://tutswiki.com/nodejs-google-app-engine/",
	"title": "How to deploy Node.js app on Google App Engine",
	"tags": [],
	"description": "Learn how to deploy your Node.js app on the Google App Engine.",
	"content": "  Till now there was no support for Node.js, but Google has just announced that developers will now be able to deploy their Node.js apps to the App Engine. Steps to deploy Node.js web service on App Engine Prerequisites   You must have a project on the Google Cloud Platform. If you don\u0026rsquo;t, create one using the GCP Console.\n  The development environment should be configured. You have 2 options here.\n Configure it on the cloud using Cloud Shell Setup your local machine  Download and install Node.js and Node Package Manager       Get Node.js and npm\n \u0026lt;div class=\u0026quot;notices note\u0026quot; \u0026gt;  Only Node.js version 8 or greater is supported on App Engine.  * Download and install Google Cloud SDK \u0026lt;a href=\u0026quot;https://cloud.google.com/sdk/docs/#install_the_latest_cloud_tools_version_cloudsdk_current_version\u0026quot; target=\u0026quot;_blank\u0026quot; class=\u0026quot;btn btn-default\u0026quot;\u0026gt;  Get Google Cloud SDK\n \u0026lt;div class=\u0026quot;notices note\u0026quot; \u0026gt;  Google Cloud SDK also installs gcloud command line tool. Hello world!  There\u0026rsquo;s a sample Node.js repository on GitHub. Either clone it using git or download the zip.  \u0026lt;!-- language: lang-sh --\u0026gt; git clone https://github.com/GoogleCloudPlatform/nodejs-docs-samples  Navigate to the below directory  \u0026lt;!-- language: lang-sh --\u0026gt; cd nodejs-docs-samples/appengine/hello-world/standard  Install the required dependencies using npm utility  \u0026lt;!-- language: lang-js --\u0026gt; npm install  Start the web server  \u0026lt;!-- language: lang-js --\u0026gt; npm start  Check output  If you are using Cloud Shell then click on Web preview If you are on Local Machine then navigate to http://localhost:8080/    Deploy on App Engine Since we have verified that our Hello World program is working fine, it\u0026rsquo;s time to deploy it.\n If you had installed Google Cloud SDK properly (as mentioned in Prerequisites), you\u0026rsquo;ll have access to the gcloud command. Run it as below  \u0026lt;!-- language: lang-sh --\u0026gt; gcloud app deploy  Your app should now be live at https://\u0026lt;PROJECT_ID\u0026gt;.appspot.com/  \u0026lt;!-- language: lang-sh --\u0026gt; gcloud app browse  That\u0026rsquo;s it. You have successfully deployed your sample Node.js app on the Google App Engine.\n"
},
{
	"uri": "http://tutswiki.com/angular6-features/",
	"title": "What&#39;s new in Angular 6 (Features List)",
	"tags": [],
	"description": "List of major changes in Angular 6. ng-add, ng-update, material, cdk and starter components.",
	"content": "Angular 6 Features:  New CLI commands  ng update ng add   Referencing providers Angular Elements Angular Material + CDK Components  Tree Badge Bottom-Sheet Overlay   Starter Components  Dashboard Side-Nav Datatable   Library Support CLI Workspaces RxJS v6 Long Term Support  ng update A new command is introduced in Angular CLI which analyzes package.json and recommends any updates (if needed) on the installed packages.\nThis is going to make your life easy as now you don\u0026rsquo;t have to manually synchronize your dependencies. This will work using Schematics, a workflow tool which is based on Tree data structure. For example a tree has base, scripts following schematics will also have a base and that base will be the root structure. Any modification has first have to pass from staging area to make its way to the root. If any of the dependency provide a schematic then it can automatically update your code whenever there are major changes.\nSo now if you run ng update @angular/common it will update the package and run any schematic available for this package.\nTo get more details on ng update usage, refer the official specification.\nng add This is another CLI command added in Angular 6. This will be helpful in adding new packages to your project. It downloads the packages (with their dependencies) using the package manager and installs them with the help of Schematics.\nng add @angular/material // Install and configure Angular Material ng add @ng-bootstrap/schematics // Add ng-bootstrap in your application This area will flourish with increase in packages supporting ng add. Refer Material\u0026rsquo;s ng-add schematic to get an idea on how to write one for your application.\nReferencing Providers Before this update we used to reference services from module but with Angular 6 we will reference module from service.\nAngular Elements @angular/elements creates a custom element which acts as a bridge between Angular component interface and change detection functionality to the built-in DOM API. You can bootstrap Angular components with your application and they will be registered as Angular Elements. One of the benefits that you get from this is that it\u0026rsquo;ll dynamically insert HTML code holding Angular components after your application is compiled.\nAngular Material + CDK Components Below are some new components that have been added in Angular 6.\n Tree: It is based on datatable component and is best suited for representing hierarchical data. CDK contains the core tree directive (cdk-tree) whereas mat-tree comes with Material design style. See this presentation from ng conf 2018 to get more details on Material Trees.   Badge: This component can be used to display a small piece of information such as notification count on notification drawer, unread emails count over the email icon etc.   Bottom-Sheet: This component is mobile-centric which can be used to present a list of options for a particular action. It appears from the bottom of the viewport (with slide-up animation).   Overlay: @angular/cdk/overlay has been updated with a new positioning logic which helps in creating intelligent pop-ups that remain on the screen in all situations.  Starter Components With Angular 6 you get 3 new starter components after running ng add @angular/material. With this update in place, it\u0026rsquo;s very easy to create simple UI.\n Create a dashboard  ng generate @angular/material:material-dashboard --name=test-dashboard  Create side navigation  ng generate @angular/material:material-nav --name=test-nav  Create a datatable  ng generate @angular/material:material-table --name=test-table Library Support Library support has been added in 6.0.0. You can easily create a library using below command. See details.\nng generate library \u0026lt;name\u0026gt; CLI Workspaces CLI can now support workspaces with multiple projects. angular-cli.json has been renamed to angular.json. Each workspace can have multiple projects, each project can have targets and each target can have a configuration.\nRxJS v6 Angular 6 supports RxJS v6. RxJS v6 ensures that only those modules are bundled in production that are being used by your application. If you are moving from the previous version to Angular 6 then you have to change import statements and operator usage to make your application work. But if you don\u0026rsquo;t want to change then you can use this new package rxjs-compat which provides backward compatibility.\nLong Term Support Angular team announced to provide long-term support for all major releases starting from version 4. LTS will include 6 months of active development + 12 months of security patches and critical bug fixes.\nOther Changes:  \u0026lt;template\u0026gt; tag has been removed so now you have to use \u0026lt;ng-template\u0026gt; instead. @angular/http is deprecated, @angular/common/http is the recommended alternative.  "
},
{
	"uri": "http://tutswiki.com/github-alternatives/",
	"title": "GitHub Alternatives (Free, Paid, Self-Hosted)",
	"tags": [],
	"description": "Popular Alternatives to GitHub for Web, Linux, Windows, Self-Hosted and more.",
	"content": "A couple of years ago Microsoft was anti-open-source.\n \u0026ldquo;Open source is an intellectual-property destroyer. I can\u0026rsquo;t imagine something that could be worse than this for the software business and the intellectual-property business.\u0026rdquo; - Jim Allchin (Former Windows chief), 2001\n  \u0026ldquo;Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.\u0026rdquo; - Steve Ballmer (Former CEO)\n However, in recent years Microsoft has tried hard to catch up with the open-source world. They are promoting themselves as a supporter of open-source. They have open-sourced some of their projects and also joined The Linux Foundation as a platinum member.\nNobody knows whether they are doing this because they accepted that open-source is good or they are just trying to stay in the business by getting the attention of open-source users. Surely there are trust issues. Some GitHub users have already started looking for alternatives.\nBelow is a list of some popular services similar to GitHub:\n1. GitLab Most of the users on Social Media seem to be choosing GitLab as a replacement for GitHub.\nFeatures:  Issue board, Issue tracker (with due dates) Built-in CI/CD Unlimited private repositories Faster file search Cherry pick changes File locking Web IDE Wiki for project Ad free Code review and comments are supported in pull requests Static/Dynamic Application Security Testing, Docker container scanning Smart Mirroring for faster clone, fetch, pull (Premium) Host static websites  2. BitBucket An Atlassian product which is the most popular alternative to GitHub.\nFeatures:  Unlimited private repositories JIRA integration 2 factor authentication LFS support Source code search Wiki for project Issue tracker Ad free Code review and comments are supported in pull requests BitBucket cloud for hosting static websites (similar to GitHub pages) Smart Mirroring for faster clone, fetch, pull (Premium)  Pricing: Bitbucket Data Center vs GitHub Enterprise 3. Gitea A lightweight GitHub clone (forked from GoGs) written in Go lang.\nFeatures:  GitHub clone Runs on Windows, Mac and Linux Lightweight (Even supports Raspberry Pi) Install from binary Ship with docker, vagrant or as a package Repo viewer Issue tracker Wiki API support Help (Support Forum and Chat)  4. SourceForge One of the oldest (since 1999) to offer free services to open source projects.\nFeatures:  Issue tracking Code hosting Mirroing Wiki Mailing lists Support forums User reviews on projects Micro-blog for project Unlimited bandwidth Download statistics Tool to import GitHub projects  5. Launchpad A Canonical product, which is quite famous for hosting Ubuntu projects.\nFeatures:  Issue tracking Code hosting (supports both Git and Bazaar) Code reviews Build and host Ubuntu projects Mailing lists Translations FAQs Specification tracking  6. Cloud Source Repositories (Paid) A Google product which is a part of Google Cloud.\nFeatures:  Connect your repo from BitBucket or GitHub Source code browser Debug and error reporting tools Stable and easily scalable infrastructure CI through Container Builder Preinstalled tools (Programming languages, Cloud shell, and Shell Editor) Faster deployment through App Engine Deployment through custom triggers (HTTP, Pub/Sub etc.)  Pricing: 7. AWS CodeCommit (Paid) An Amazon product which is similar to Cloud Source Repo, if you already have an AWS account you get it for free (Maximum 5 users allowed per month).\nFeatures:  Hosted on AWS Encrypted repositories Code review and comments are supported in pull requests Scalable No limit on size or type of data Easy migration from other services  Pricing: 8. Phabricator (Self-hosted) Features:  Source code hosting Git, Mercurial, SVN support Code review and auditing Wiki Issue tracker Workboard Chat channel Command line tools (lint, unit-tests) API support  Pricing: 9. GitBucket (Self-hosted) A git platform on JVM.\nFeatures:  Powered with Scala Highly scalable GitHub API compatible Repo viewer Issue tracker Wiki Plugin support  10. GoGs (Self-hosted) An easy to install and lightweight GitHub clone written in Go.\nFeatures:  GitHub clone Install from binary Ship with docker, vagrant or as a package Cross platform support Lightweight (runs on Raspberry Pi) Repo viewer Issue tracker Wiki  11. GitPrep (Self-hosted) A GitHub clone written in Perl.\nFeatures:  GitHub clone Portable Issue tracker CGI support Built-in web server SSL Support Public key auth support  12. Allura (Self-hosted) A product from Apache. Sourceforge runs on Allura.\nFeatures:  Code repo Supports Git, Mercurial, SVN Issue tracker Discussion forums Wiki Mailing lists  "
},
{
	"uri": "http://tutswiki.com/what-is-the-use-of-yield-in-python/",
	"title": "What is the use of yield in Python?",
	"tags": ["python"],
	"description": "What does yield do? How is it different from return?",
	"content": "References  What does the “yield” keyword do in Python? Yield expressions  "
},
{
	"uri": "http://tutswiki.com/append-vs-extend-python/",
	"title": "Difference between append and extend in Python",
	"tags": ["python"],
	"description": "What is the difference between list methods append and extend in Python?",
	"content": "append and extend are list methods in Python which can be used to combine multiple lists. But what is the difference between them? When should you use one over another, let\u0026rsquo;s find out.\nThe official documentation describes them as:\n  list.append(x): Add an item to the end of the list; equivalent to a[len(a):] = [x].\n  list.extend(L): Extend the list by appending all the items in the given list; equivalent to a[len(a):] = L.\n  Notice the bold words in the definition. append adds an item and extend appends all the items of the given list.\nLet\u0026rsquo;s take an example:\nappend a list to another list in Python some_list = [\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5] another_list = [\u0026#39;new data\u0026#39;, 12] some_list.append(another_list) print some_list Output:\n[\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5, [\u0026#39;new data\u0026#39;, 12]] As you can see, the append method took an item i.e. the object of another list and added it to some_list as it is.\nextend a list with another list in Python some_list = [\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5] another_list = [\u0026#39;new data\u0026#39;, 12] some_list.extend(another_list) print some_list Output:\n[\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5, \u0026#39;new data\u0026#39;, 12] In case of extend you can see that all the items from another_list were appended to some_list one by one. So you can say extend method concatenates one list with another list.\nQuiz Q: What will be the output of below code:\nsome_list = [\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5] data = \u0026#39;hello\u0026#39; some_list.extend(data) print some_list A: Output is\n[\u0026#39;string\u0026#39;, 1, \u0026#39;another string\u0026#39;, 6.5, \u0026#39;h\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;] Explanation: If you notice carefully, data is a string and strings in Python are iterable. Therefore the extend method iterated over all characters in the string one by one and appended them to the list.\nSo based on above we can say that below 2 code snippets are equivalent:\nfor data in iterator: some_list.append(data) some_list.extend(iterator) "
},
{
	"uri": "http://tutswiki.com/print-same-line-python/",
	"title": "How to print on same line with print in Python",
	"tags": ["python"],
	"description": "Use a comma at the end of print function to write the data on same line",
	"content": "In Python, when you use the print function, it prints a new line at the end.\nFor example:\nprint \u0026#34;This is some line.\u0026#34; print \u0026#34;This is another line.\u0026#34; Output:\nThis is some line. This is another line. What if you want to avoid the newline and want to print both statements on same line? Well, there are 2 possible solutions.\nAdd comma at the end of print print \u0026#34;This is some line.\u0026#34;, print \u0026#34;This is another line.\u0026#34; Output:\nThis is some line. This is another line. If you are using Python 3 then use the below:\nprint (\u0026#34;This is some line.\u0026#34;, end=\u0026#34;\u0026#34;) print (\u0026#34;This is another line.\u0026#34;) Use sys module import sys sys.stdout.write(\u0026#34;This is some line.\u0026#34;) sys.stdout.write(\u0026#34;This is another line.\u0026#34;) "
},
{
	"uri": "http://tutswiki.com/read-write-config-files-in-python/",
	"title": "Writing and Reading config files in Python",
	"tags": ["python"],
	"description": "Learn how to write and read config files in Python using configparser module.",
	"content": "I\u0026rsquo;m sure you must be aware about the importance of configuration files. Config files help creating the initial settings for any project, they help avoiding the hardcoded data.\nImagine if you migrate your server to a new host and suddenly your application stops working, now you have to go through your code and search/replace IP address of host at all the places. Config file comes to the rescue in such situation. You define the IP address key in config file and use it throughout your code. Later when you want to change any attribute, just change it in the config file. So helpful, isn\u0026rsquo;t it?\nLet\u0026rsquo;s see how can we create and read config files in Python.\nCreating config file in Python In Python we have configparser module which can help us with creation of config files (.ini format).\nfrom configparser import ConfigParser #Get the configparser object config_object = ConfigParser() #Assume we need 2 sections in the config file, let\u0026#39;s call them USERINFO and SERVERCONFIG config_object[\u0026#34;USERINFO\u0026#34;] = { \u0026#34;admin\u0026#34;: \u0026#34;Chankey Pathak\u0026#34;, \u0026#34;loginid\u0026#34;: \u0026#34;chankeypathak\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;tutswiki\u0026#34; } config_object[\u0026#34;SERVERCONFIG\u0026#34;] = { \u0026#34;host\u0026#34;: \u0026#34;tutswiki.com\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;8080\u0026#34;, \u0026#34;ipaddr\u0026#34;: \u0026#34;8.8.8.8\u0026#34; } #Write the above sections to config.ini file with open(\u0026#39;config.ini\u0026#39;, \u0026#39;w\u0026#39;) as conf: config_object.write(conf) Now if you check the working directory, you will notice config.ini file has been created, below is its content.\n[USERINFO] admin = Chankey Pathak password = tutswiki loginid = chankeypathak [SERVERCONFIG] host = tutswiki.com ipaddr = 8.8.8.8 port = 8080 Reading a key from config file So we have created a config file, now in your code you have to read the configuration data so that you can use it by \u0026ldquo;keyname\u0026rdquo; to avoid hardcoded data, let\u0026rsquo;s see how to do that.\nfrom configparser import ConfigParser #Read config.ini file config_object = ConfigParser() config_object.read(\u0026#34;config.ini\u0026#34;) #Get the password userinfo = config_object[\u0026#34;USERINFO\u0026#34;] print \u0026#34;Password is {}\u0026#34;.format(userinfo[\u0026#34;password\u0026#34;]) Output:\nPassword is tutswiki Updating a key in config file Suppose you have updated the password for chankeypathak user. You can update the same in config file using below:\nfrom configparser import ConfigParser #Read config.ini file config_object = ConfigParser() config_object.read(\u0026#34;config.ini\u0026#34;) #Get the USERINFO section userinfo = config_object[\u0026#34;USERINFO\u0026#34;] #Update the password userinfo[\u0026#34;password\u0026#34;] = \u0026#34;newpassword\u0026#34; #Write changes back to file with open(\u0026#39;config.ini\u0026#39;, \u0026#39;w\u0026#39;) as conf: config_object.write(conf) Now if you open the config.ini file, you will notice that the password has been updated.\n"
},
{
	"uri": "http://tutswiki.com/run-module-as-script-python/",
	"title": "How to run a Python module as script?",
	"tags": ["python"],
	"description": "If you want to run the module itself as a script then you should use the __name__ variable.",
	"content": "Suppose you have a module named mymath.py, which has a couple of functions. You can import this module in your script and call these functions.\ndef int_sum(a, b): print a+b def some_other_function(): pass But, what if you want to run the module itself as a script?\nWell, if you want to use a Python module as script then you just have to use the conditional for __name__.\ndef int_sum(a, b): print a+b if __name__ == \u0026#34;__main__\u0026#34;: import sys int_sum(int(sys.argv[1]),int(sys.argv[2])) Now you can run the above as:\n$ python mymath.py 1 2 3 This works because the value of built-in __name__ variable is set to __main__ if the Python code is executed directly through the interpreter. If you use the above module in a script using import then in that case the value of __name__ is the filename of module.\nAlso see  PEP 338 \u0026ndash; Executing modules as scripts What is if name == \u0026ldquo;main\u0026rdquo; in Python? What is the difference between a module and a script in Python?  "
},
{
	"uri": "http://tutswiki.com/if-name-main-in-python/",
	"title": "What is if __name__ == &#34;__main__&#34; in Python?",
	"tags": ["python"],
	"description": "If you are new to Python then you may have noticed if __name__ == &#34;__main__&#34; line in some python codes.",
	"content": "If you are new to Python then you may have noticed if __name__ == \u0026quot;__main__\u0026quot; line in some python codes.\nYou may be wondering:\n What does that mean? What purpose does it serve? I don\u0026rsquo;t see it in all Python codes, so when should I use it exactly? Can you give me some examples?  Let me try to explain the above to you.\nIn Python all modules have some built-in attributes. __name__ is one of them. Now the question is what does __name__ contain?\nWell, that depends actually. It depends on how you use the module.\nCase 1: Running the module directly If you run the module directly in a standalone program then in that case the value of __name__ attribute is set to __main__.\nFor example, create a file main.py and enter below code.\nif __name__ == \u0026#34;__main__\u0026#34;: print \u0026#34;Directly called from python interpreter\u0026#34; print \u0026#34;Value of __name__ attribute is \u0026#34;+__name__ else: print \u0026#34;Not directly called\u0026#34; print \u0026#34;Value of __name__ attribute is \u0026#34;+__name__ Now run the above code as below:\n$ python main.py Output:\nDirectly called from Python interpreter Value of __name__ attribute is __main__ Notice that when we ran the program directly from python interpreter the conditional __name__ == __main__ returned True and the print statement inside the if block got executed.\nCase 2: Using the module with import If you use the module in another program (using the import function), then in that case the value of __name__ attribute is set to the filename of the module.\nLet\u0026rsquo;s try to import the above created main.py.\n$ python \u0026gt;\u0026gt;\u0026gt; import main.py Output:\nNot directly called Value of __name__ attribute is main References  __main__ — Top-level script environment What does if __name__ == “__main__”: do?  "
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter1/",
	"title": "Chapter 1 - Reading from a CSV",
	"tags": [],
	"description": "Read data from a CSV using pandas dataframe",
	"content": "# Render our plots inline %matplotlib inline import pandas as pd import matplotlib.pyplot as plt pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) # Make the graphs a bit prettier plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) 1.1 Reading data from a CSV file You can read data from a CSV file using the read_csv function. By default, it assumes that the fields are comma-separated.\nWe\u0026rsquo;re going to be looking some cyclist data from Montréal. Here\u0026rsquo;s the original page (in French). We\u0026rsquo;re using the data from 2012. Download the bikes.csv file to try out the below examples.\nThis dataset is a list of how many people were on 7 different bike paths in Montreal, each day.\nimport pandas as pd broken_df = pd.read_csv(\u0026#39;bikes.csv\u0026#39;) # Look at the first 3 rows broken_df[:3] Output:\nYou\u0026rsquo;ll notice that this is totally broken! read_csv has a bunch of options that will let us fix that, though. Here we\u0026rsquo;ll\n Change the column separator to a ; Set the encoding to '_latin1_' (the default is '_utf8_') Parse the dates in the 'Date' column Tell it that our dates have the date first instead of the month first Set the index to be the 'Date' column  fixed_df = pd.read_csv(\u0026#39;bikes.csv\u0026#39;, sep=\u0026#39;;\u0026#39;, encoding=\u0026#39;latin1\u0026#39;, parse_dates=[\u0026#39;Date\u0026#39;], dayfirst=True, index_col=\u0026#39;Date\u0026#39;) fixed_df[:3] Output:\n1.2 Selecting a column When you read a CSV, you get a kind of object called a DataFrame, which is made up of rows and columns. You get columns out of a DataFrame the same way you get elements out of a dictionary.\nHere\u0026rsquo;s an example:\nfixed_df[\u0026#39;Berri 1\u0026#39;] Output:\nDate 2012-01-01 35 2012-01-02 83 2012-01-03 135 2012-01-04 144 2012-01-05 197 2012-01-06 146 2012-01-07 98 2012-01-08 95 2012-01-09 244 2012-01-10 397 2012-01-11 273 2012-01-12 157 2012-01-13 75 2012-01-14 32 2012-01-15 54 ... 2012-10-22 3650 2012-10-23 4177 2012-10-24 3744 2012-10-25 3735 2012-10-26 4290 2012-10-27 1857 2012-10-28 1310 2012-10-29 2919 2012-10-30 2887 2012-10-31 2634 2012-11-01 2405 2012-11-02 1582 2012-11-03 844 2012-11-04 966 2012-11-05 2247 Name: Berri 1, Length: 310, dtype: int64 1.3 Plotting a column Just add .plot() to the end! How could it be easier? =)\nWe can see that, unsurprisingly, not many people are biking in January, February, and March.\nimport pandas as pd import matplotlib.pyplot as plt fixed_df = pd.read_csv(\u0026#39;bikes.csv\u0026#39;, sep=\u0026#39;;\u0026#39;, encoding=\u0026#39;latin1\u0026#39;, parse_dates=[\u0026#39;Date\u0026#39;], dayfirst=True, index_col=\u0026#39;Date\u0026#39;) fixed_df[\u0026#39;Berri 1\u0026#39;].plot() Output:\nfixed_df.plot(figsize=(15, 10)) plt.show() Output:\n1.4 Putting all that together Here\u0026rsquo;s the code we needed to write do draw that graph, all together:\ndf = pd.read_csv(\u0026#39;bikes.csv\u0026#39;, sep=\u0026#39;;\u0026#39;, encoding=\u0026#39;latin1\u0026#39;, parse_dates=[\u0026#39;Date\u0026#39;], dayfirst=True, index_col=\u0026#39;Date\u0026#39;) df[\u0026#39;Berri 1\u0026#39;].plot() Output:\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter2/",
	"title": "Chapter 2 - Selecting and finding desired data",
	"tags": [],
	"description": "Select data from a pandas dataframe, take slices and get columns",
	"content": "# The usual preamble %matplotlib inline import pandas as pd import matplotlib.pyplot as plt # Make the graphs a bit prettier, and bigger pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) # This is necessary to show lots of columns in pandas 0.12.  # Not necessary in pandas 0.13. pd.set_option(\u0026#39;display.width\u0026#39;, 5000) pd.set_option(\u0026#39;display.max_columns\u0026#39;, 60) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) We\u0026rsquo;re going to use a new dataset here, to demonstrate how to deal with larger datasets. This is a subset of the of 311 service requests from NYC Open Data. Download the file 311-service-requests.csv.\ncomplaints = pd.read_csv(\u0026#39;311-service-requests.csv\u0026#39;) Depending on your pandas version, you might see an error like \u0026quot;DtypeWarning: Columns (8) have mixed types\u0026quot;. This means that it\u0026rsquo;s encountered a problem reading in our data. In this case it almost certainly means that it has columns where some of the entries are strings and some are integers.\nFor now we\u0026rsquo;re going to ignore it and hope we don\u0026rsquo;t run into a problem, but in the long run we\u0026rsquo;d need to investigate this warning.\n2.1 What\u0026rsquo;s even in it? (the summary) When you print a large dataframe, it will only show you the first few rows. If you don\u0026rsquo;t see this, don\u0026rsquo;t panic! The default behavior for large dataframes changed between pandas 0.12 and 0.13. Previous to 0.13 it would show you a summary of the dataframe. This includes all the columns, and how many non-null values there are in each column.\ncomplaints Output:\n2.2 Selecting columns and rows To select a column, we index with the name of the column, like this:\ncomplaints[\u0026#39;Complaint Type\u0026#39;] Output:\n0 Noise - Street/Sidewalk 1 Illegal Parking 2 Noise - Commercial 3 Noise - Vehicle 4 Rodent 5 Noise - Commercial 6 Blocked Driveway 7 Noise - Commercial 8 Noise - Commercial 9 Noise - Commercial 10 Noise - House of Worship 11 Noise - Commercial 12 Illegal Parking 13 Noise - Vehicle 14 Rodent ... 111054 Noise - Street/Sidewalk 111055 Noise - Commercial 111056 Street Sign - Missing 111057 Noise 111058 Noise - Commercial 111059 Noise - Street/Sidewalk 111060 Noise 111061 Noise - Commercial 111062 Water System 111063 Water System 111064 Maintenance or Facility 111065 Illegal Parking 111066 Noise - Street/Sidewalk 111067 Noise - Commercial 111068 Blocked Driveway Name: Complaint Type, Length: 111069, dtype: object To get the first 5 rows of a dataframe, we can use a slice: df[:5]. This is a great way to get a sense for what kind of information is in the dataframe \u0026ndash; take a minute to look at the contents and get a feel for this dataset.\ncomplaints[:5] Output:\nWe can combine these to get the first 5 rows of a column:\ncomplaints[\u0026#39;Complaint Type\u0026#39;][:5] Output:\n0 Noise - Street/Sidewalk 1 Illegal Parking 2 Noise - Commercial 3 Noise - Vehicle 4 Rodent Name: Complaint Type, dtype: object and it doesn\u0026rsquo;t matter which direction we do it in:\ncomplaints[\u0026#39;Complaint Type\u0026#39;][:5] Output:\n0 Noise - Street/Sidewalk 1 Illegal Parking 2 Noise - Commercial 3 Noise - Vehicle 4 Rodent Name: Complaint Type, dtype: object 2.3 Selecting multiple columns What if we just want to know the complaint type and the borough, but not the rest of the information? Pandas makes it really easy to select a subset of the columns: just index with list of columns you want.\ncomplaints[[\u0026#39;Complaint Type\u0026#39;, \u0026#39;Borough\u0026#39;]] Output:\nThat showed us a summary, and then we can look at the first 10 rows:\ncomplaints[[\u0026#39;Complaint Type\u0026#39;, \u0026#39;Borough\u0026#39;]][:10] Output:\n2.4 What\u0026rsquo;s the most common complaint type? This is a really easy question to answer! There\u0026rsquo;s a .value_counts() method that we can use:\ncomplaints[\u0026#39;Complaint Type\u0026#39;].value_counts() Output:\nHEATING 14200 GENERAL CONSTRUCTION 7471 Street Light Condition 7117 DOF Literature Request 5797 PLUMBING 5373 PAINT - PLASTER 5149 Blocked Driveway 4590 NONCONST 3998 Street Condition 3473 Illegal Parking 3343 Noise 3321 Traffic Signal Condition 3145 Dirty Conditions 2653 Water System 2636 Noise - Commercial 2578 ... Opinion for the Mayor 2 Window Guard 2 DFTA Literature Request 2 Legal Services Provider Complaint 2 Open Flame Permit 1 Snow 1 Municipal Parking Facility 1 X-Ray Machine/Equipment 1 Stalled Sites 1 DHS Income Savings Requirement 1 Tunnel Condition 1 Highway Sign - Damaged 1 Ferry Permit 1 Trans Fat 1 DWD 1 Length: 165, dtype: int64 If we just wanted the top 10 most common complaints, we can do this:\ncomplaint_counts = complaints[\u0026#39;Complaint Type\u0026#39;].value_counts() complaint_counts[:10] Output:\nHEATING 14200 GENERAL CONSTRUCTION 7471 Street Light Condition 7117 DOF Literature Request 5797 PLUMBING 5373 PAINT - PLASTER 5149 Blocked Driveway 4590 NONCONST 3998 Street Condition 3473 Illegal Parking 3343 dtype: int64 But it gets better! We can plot them!\ncomplaint_counts[:10].plot(kind=\u0026#39;bar\u0026#39;) Output:\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter3/",
	"title": "Chapter 3 - Filtering dataframes",
	"tags": [],
	"description": "Here we get into serious slicing and dicing and learn how to filter dataframes in complicated ways, really fast.",
	"content": "# The usual preamble %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np # Make the graphs a bit prettier, and bigger pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) # This is necessary to show lots of columns in pandas 0.12.  # Not necessary in pandas 0.13. pd.set_option(\u0026#39;display.width\u0026#39;, 5000) pd.set_option(\u0026#39;display.max_columns\u0026#39;, 60) Let\u0026rsquo;s continue with our NYC 311 service requests example.\ncomplaints = pd.read_csv(\u0026#39;311-service-requests.csv\u0026#39;) 3.1 Selecting only noise complaints I\u0026rsquo;d like to know which borough has the most noise complaints. First, we\u0026rsquo;ll take a look at the data to see what it looks like:\ncomplaints[:5] Output:\nTo get the noise complaints, we need to find the rows where the \u0026ldquo;Complaint Type\u0026rdquo; column is \u0026ldquo;Noise - Street/Sidewalk\u0026rdquo;. I\u0026rsquo;ll show you how to do that, and then explain what\u0026rsquo;s going on.\nnoise_complaints = complaints[complaints[\u0026#39;Complaint Type\u0026#39;] == \u0026#34;Noise - Street/Sidewalk\u0026#34;] noise_complaints[:3] Output:\nIf you look at noise_complaints, you\u0026rsquo;ll see that this worked, and it only contains complaints with the right complaint type. But how does this work? Let\u0026rsquo;s deconstruct it into two pieces\ncomplaints[\u0026#39;Complaint Type\u0026#39;] == \u0026#34;Noise - Street/Sidewalk\u0026#34; Output:\n0 True 1 False 2 False 3 False 4 False 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False ... 111054 True 111055 False 111056 False 111057 False 111058 False 111059 True 111060 False 111061 False 111062 False 111063 False 111064 False 111065 False 111066 True 111067 False 111068 False Name: Complaint Type, Length: 111069, dtype: bool This is a big array of Trues and Falses, one for each row in our dataframe. When we index our dataframe with this array, we get just the rows where our boolean array evaluated to True. It\u0026rsquo;s important to note that for row filtering by a boolean array the length of our dataframe\u0026rsquo;s index must be the same length as the boolean array used for filtering.\nYou can also combine more than one condition with the \u0026amp; operator like this:\nis_noise = complaints[\u0026#39;Complaint Type\u0026#39;] == \u0026#34;Noise - Street/Sidewalk\u0026#34; in_brooklyn = complaints[\u0026#39;Borough\u0026#39;] == \u0026#34;BROOKLYN\u0026#34; complaints[is_noise \u0026amp; in_brooklyn][:5] Output:\nOr if we just wanted a few columns:\ncomplaints[is_noise \u0026amp; in_brooklyn][[\u0026#39;Complaint Type\u0026#39;, \u0026#39;Borough\u0026#39;, \u0026#39;Created Date\u0026#39;, \u0026#39;Descriptor\u0026#39;]][:10] Output:\n3.2 A digression about numpy arrays On the inside, the type of a column is pd.Series\npd.Series([1,2,3]) Output:\n0 1 1 2 2 3 dtype: int64 and pandas Series are internally numpy arrays. If you add .values to the end of any Series, you\u0026rsquo;ll get its internal numpy array\nnp.array([1,2,3]) Output:\narray([1, 2, 3]) pd.Series([1,2,3]).values Output:\narray([1, 2, 3]) So this binary-array-selection business is actually something that works with any numpy array:\narr = np.array([1,2,3]) arr != 2 Output:\narray([ True, False, True], dtype=bool) arr[arr != 2] Output:\narray([1, 3]) 3.3 So, which borough has the most noise complaints? is_noise = complaints[\u0026#39;Complaint Type\u0026#39;] == \u0026#34;Noise - Street/Sidewalk\u0026#34; noise_complaints = complaints[is_noise] noise_complaints[\u0026#39;Borough\u0026#39;].value_counts() Output:\nMANHATTAN 917 BROOKLYN 456 BRONX 292 QUEENS 226 STATEN ISLAND 36 Unspecified 1 dtype: int64 It\u0026rsquo;s Manhattan! But what if we wanted to divide by the total number of complaints, to make it make a bit more sense? That would be easy too:\nnoise_complaint_counts = noise_complaints[\u0026#39;Borough\u0026#39;].value_counts() complaint_counts = complaints[\u0026#39;Borough\u0026#39;].value_counts() noise_complaint_counts / complaint_counts Output:\nBRONX 0 BROOKLYN 0 MANHATTAN 0 QUEENS 0 STATEN ISLAND 0 Unspecified 0 dtype: int64 Oops, why was that zero? That\u0026rsquo;s no good. This is because of integer division in Python 2. Let\u0026rsquo;s fix it, by converting complaint_counts into an array of floats.\nnoise_complaint_counts / complaint_counts.astype(float) Output:\nBRONX 0.014833 BROOKLYN 0.013864 MANHATTAN 0.037755 QUEENS 0.010143 STATEN ISLAND 0.007474 Unspecified 0.000141 dtype: float64 Now let\u0026rsquo;s plot it!\n(noise_complaint_counts / complaint_counts.astype(float)).plot(kind=\u0026#39;bar\u0026#39;) Output:\nSo Manhattan really does complain more about noise than the other boroughs! Neat.\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter4/",
	"title": "Chapter 4 - Groupby and Aggregate",
	"tags": [],
	"description": "Find out on which weekday people bike the most with groupby and aggregate",
	"content": "%matplotlib inline import pandas as pd import matplotlib.pyplot as plt pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) # Make the graphs a bit prettier plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 5) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#39;sans-serif\u0026#39; # This is necessary to show lots of columns in pandas 0.12.  # Not necessary in pandas 0.13. pd.set_option(\u0026#39;display.width\u0026#39;, 5000) pd.set_option(\u0026#39;display.max_columns\u0026#39;, 60) Okay! We\u0026rsquo;re going back to our bike path dataset here. I live in Montreal, and I was curious about whether we\u0026rsquo;re more of a commuter city or a biking-for-fun city \u0026ndash; do people bike more on weekends, or on weekdays?\n4.1 Adding a \u0026lsquo;weekday\u0026rsquo; column to our dataframe First, we need to load up the data. We\u0026rsquo;ve done this before.\nbikes = pd.read_csv(\u0026#39;bikes.csv\u0026#39;, sep=\u0026#39;;\u0026#39;, encoding=\u0026#39;latin1\u0026#39;, parse_dates=[\u0026#39;Date\u0026#39;], dayfirst=True, index_col=\u0026#39;Date\u0026#39;) bikes[\u0026#39;Berri 1\u0026#39;].plot() Output:\nNext up, we\u0026rsquo;re just going to look at the Berri bike path. Berri is a street in Montreal, with a pretty important bike path. I use it mostly on my way to the library now, but I used to take it to work sometimes when I worked in Old Montreal. So we\u0026rsquo;re going to create a dataframe with just the Berri bikepath in it\nberri_bikes = bikes[[\u0026#39;Berri 1\u0026#39;]].copy() berri_bikes[:5] Output:\nNext, we need to add a \u0026lsquo;weekday\u0026rsquo; column. Firstly, we can get the weekday from the index. We haven\u0026rsquo;t talked about indexes yet, but the index is what\u0026rsquo;s on the left on the above dataframe, under \u0026lsquo;Date\u0026rsquo;. It\u0026rsquo;s basically all the days of the year.\nberri_bikes.index Output:\n\u0026lt;class \u0026#39;pandas.tseries.index.DatetimeIndex\u0026#39;\u0026gt; [2012-01-01, ..., 2012-11-05] Length: 310, Freq: None, Timezone: None You can see that actually some of the days are missing \u0026ndash; only 310 days of the year are actually there. Who knows why. Pandas has a bunch of really great time series functionality, so if we wanted to get the day of the month for each row, we could do it like this:\nberri_bikes.index.day Output:\narray([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 1, 2, 3, 4, 5], dtype=int32) We actually want the weekday, though:\nberri_bikes.index.weekday Output:\narray([6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0], dtype=int32) These are the days of the week, where 0 is Monday. I found out that 0 was Monday by checking on a calendar.\nNow that we know how to get the weekday, we can add it as a column in our dataframe like this:\nberri_bikes.loc[:,\u0026#39;weekday\u0026#39;] = berri_bikes.index.weekday berri_bikes[:5] Output:\n4.2 Adding up the cyclists by weekday This turns out to be really easy! Dataframes have a .groupby() method that is similar to SQL groupby, if you\u0026rsquo;re familiar with that. I\u0026rsquo;m not going to explain more about it right now \u0026ndash; if you want to to know more, the documentation is really good.\nIn this case, berri_bikes.groupby('weekday').aggregate(sum) means\n \u0026ldquo;Group the rows by weekday and then add up all the values with the same weekday.\u0026rdquo;\n weekday_counts = berri_bikes.groupby(\u0026#39;weekday\u0026#39;).aggregate(sum) weekday_counts Output:\nIt\u0026rsquo;s hard to remember what 0, 1, 2, 3, 4, 5, 6 mean, so we can fix it up and graph it:\nweekday_counts.index = [\u0026#39;Monday\u0026#39;, \u0026#39;Tuesday\u0026#39;, \u0026#39;Wednesday\u0026#39;, \u0026#39;Thursday\u0026#39;, \u0026#39;Friday\u0026#39;, \u0026#39;Saturday\u0026#39;, \u0026#39;Sunday\u0026#39;] weekday_counts Output:\nweekday_counts.plot(kind=\u0026#39;bar\u0026#39;) Output:\nSo it looks like Montrealers are commuter cyclists \u0026ndash; they bike much more during the week. Neat!\n4.3 Putting it together Let\u0026rsquo;s put all that together, to prove how easy it is. 6 lines of magical pandas! If you want to play around, try changing sum to max, numpy.median, or any other function you like.\nbikes = pd.read_csv(\u0026#39;../data/bikes.csv\u0026#39;, sep=\u0026#39;;\u0026#39;, encoding=\u0026#39;latin1\u0026#39;, parse_dates=[\u0026#39;Date\u0026#39;], dayfirst=True, index_col=\u0026#39;Date\u0026#39;) # Add the weekday column berri_bikes = bikes[[\u0026#39;Berri 1\u0026#39;]].copy() berri_bikes.loc[:,\u0026#39;weekday\u0026#39;] = berri_bikes.index.weekday # Add up the number of cyclists by weekday, and plot! weekday_counts = berri_bikes.groupby(\u0026#39;weekday\u0026#39;).aggregate(sum) weekday_counts.index = [\u0026#39;Monday\u0026#39;, \u0026#39;Tuesday\u0026#39;, \u0026#39;Wednesday\u0026#39;, \u0026#39;Thursday\u0026#39;, \u0026#39;Friday\u0026#39;, \u0026#39;Saturday\u0026#39;, \u0026#39;Sunday\u0026#39;] weekday_counts.plot(kind=\u0026#39;bar\u0026#39;) Output:\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter5/",
	"title": "Chapter 5 - Web scraping with Pandas",
	"tags": [],
	"description": "Web scraping with Pandas",
	"content": "%matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 3) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#39;sans-serif\u0026#39; Summary By the end of this chapter, we\u0026rsquo;re going to have downloaded all of Canada\u0026rsquo;s weather data for 2012, and saved it to a CSV.\nWe\u0026rsquo;ll do this by downloading it one month at a time, and then combining all the months together.\nHere\u0026rsquo;s the temperature every hour for 2012! Download weather_2012.csv and try yourself.\nweather_2012_final = pd.read_csv(\u0026#39;weather_2012.csv\u0026#39;, index_col=\u0026#39;Date/Time\u0026#39;) weather_2012_final[\u0026#39;Temp (C)\u0026#39;].plot(figsize=(15, 6)) Output:\n5.1 Downloading one month of weather data When playing with the cycling data, I wanted temperature and precipitation data to find out if people like biking when it\u0026rsquo;s raining. So I went to the site for Canadian historical weather data, and figured out how to get it automatically.\nHere we\u0026rsquo;re going to get the data for March 2012, and clean it up\nHere\u0026rsquo;s an URL template you can use to get data in Montreal.\nurl_template = \u0026#34;http://climate.weather.gc.ca/climate_data/bulk_data_e.html?format=csv\u0026amp;stationID=5415\u0026amp;Year={year}\u0026amp;Month={month}\u0026amp;timeframe=1\u0026amp;submit=Download+Data\u0026#34; To get the data for March 2013, we need to format it with month=3, year=2012.\nurl = url_template.format(month=3, year=2012) weather_mar2012 = pd.read_csv(url, index_col=\u0026#39;Date/Time\u0026#39;, parse_dates=True) This is super great! We can just use the same read_csv function as before, and just give it a URL as a filename. Awesome.\nThere are 16 rows of metadata at the top of this CSV, but pandas knows CSVs are weird, so there\u0026rsquo;s a skiprows options. We parse the dates again, and set \u0026lsquo;Date/Time\u0026rsquo; to be the index column. Here\u0026rsquo;s the resulting dataframe.\nweather_mar2012 Output:\nLet\u0026rsquo;s plot it!\nweather_mar2012[u\u0026#34;Temp (\\xc2\\xb0C)\u0026#34;].plot(figsize=(15, 5)) Output:\nNotice how it goes up to 25° C in the middle there? That was a big deal. It was March, and people were wearing shorts outside.\nAnd I was out of town and I missed it. Still sad, humans.\nI had to write \u0026lsquo;\\xb0\u0026rsquo; for that degree character °. Let\u0026rsquo;s fix up the columns. We\u0026rsquo;re going to just print them out, copy, and fix them up by hand.\nweather_mar2012.columns = [ u\u0026#39;Year\u0026#39;, u\u0026#39;Month\u0026#39;, u\u0026#39;Day\u0026#39;, u\u0026#39;Time\u0026#39;, u\u0026#39;Data Quality\u0026#39;, u\u0026#39;Temp (C)\u0026#39;, u\u0026#39;Temp Flag\u0026#39;, u\u0026#39;Dew Point Temp (C)\u0026#39;, u\u0026#39;Dew Point Temp Flag\u0026#39;, u\u0026#39;Rel Hum (%)\u0026#39;, u\u0026#39;Rel Hum Flag\u0026#39;, u\u0026#39;Wind Dir (10s deg)\u0026#39;, u\u0026#39;Wind Dir Flag\u0026#39;, u\u0026#39;Wind Spd (km/h)\u0026#39;, u\u0026#39;Wind Spd Flag\u0026#39;, u\u0026#39;Visibility (km)\u0026#39;, u\u0026#39;Visibility Flag\u0026#39;, u\u0026#39;Stn Press (kPa)\u0026#39;, u\u0026#39;Stn Press Flag\u0026#39;, u\u0026#39;Hmdx\u0026#39;, u\u0026#39;Hmdx Flag\u0026#39;, u\u0026#39;Wind Chill\u0026#39;, u\u0026#39;Wind Chill Flag\u0026#39;, u\u0026#39;Weather\u0026#39;] You\u0026rsquo;ll notice in the summary above that there are a few columns which are are either entirely empty or only have a few values in them. Let\u0026rsquo;s get rid of all of those with dropna.\nThe argument axis=1 to dropna means \u0026ldquo;drop columns\u0026rdquo;, not rows\u0026rdquo;, and how='any' means \u0026ldquo;drop the column if any value is null\u0026rdquo;.\nThis is much better now \u0026ndash; we only have columns with real data.\nweather_mar2012 = weather_mar2012.dropna(axis=1, how=\u0026#39;any\u0026#39;) weather_mar2012[:5] Output:\nThe Year/Month/Day/Time columns are redundant, though, and the Data Quality column doesn\u0026rsquo;t look too useful. Let\u0026rsquo;s get rid of those.\nThe axis=1 argument means \u0026ldquo;Drop columns\u0026rdquo;, like before. The default for operations like dropna and drop is always to operate on rows.\nweather_mar2012 = weather_mar2012.drop([\u0026#39;Year\u0026#39;, \u0026#39;Month\u0026#39;, \u0026#39;Day\u0026#39;, \u0026#39;Time\u0026#39;, \u0026#39;Data Quality\u0026#39;], axis=1) weather_mar2012[:5] Output:\nAwesome! We now only have the relevant columns, and it\u0026rsquo;s much more manageable.\n5.2 Plotting the temperature by hour of day This one\u0026rsquo;s just for fun \u0026ndash; we\u0026rsquo;ve already done this before, using groupby and aggregate! We will learn whether or not it gets colder at night. Well, obviously. But let\u0026rsquo;s do it anyway.\ntemperatures = weather_mar2012[[u\u0026#39;Temp (C)\u0026#39;]].copy() print(temperatures.head) temperatures.loc[:,\u0026#39;Hour\u0026#39;] = weather_mar2012.index.hour temperatures.groupby(\u0026#39;Hour\u0026#39;).aggregate(np.median).plot() Output:\nDate/Time 2012-03-01 00:00:00 -5.5 2012-03-01 01:00:00 -5.7 2012-03-01 02:00:00 -5.4 2012-03-01 03:00:00 -4.7 2012-03-01 04:00:00 -5.4 2012-03-01 05:00:00 -5.3 2012-03-01 06:00:00 -5.2 2012-03-01 07:00:00 -4.9 2012-03-01 08:00:00 -5.0 2012-03-01 09:00:00 -4.9 2012-03-01 10:00:00 -4.7 2012-03-01 11:00:00 -4.4 2012-03-01 12:00:00 -4.3 2012-03-01 13:00:00 -4.3 2012-03-01 14:00:00 -3.9 2012-03-01 15:00:00 -3.3 2012-03-01 16:00:00 -2.7 2012-03-01 17:00:00 -2.9 2012-03-01 18:00:00 -3.0 2012-03-01 19:00:00 -3.6 2012-03-01 20:00:00 -3.7 2012-03-01 21:00:00 -3.9 2012-03-01 22:00:00 -4.3 2012-03-01 23:00:00 -4.3 2012-03-02 00:00:00 -4.8 2012-03-02 01:00:00 -5.3 2012-03-02 02:00:00 -5.2 2012-03-02 03:00:00 -5.5 2012-03-02 04:00:00 -5.6 2012-03-02 05:00:00 -5.5 ... ... 2012-03-30 18:00:00 3.9 2012-03-30 19:00:00 3.1 2012-03-30 20:00:00 3.0 2012-03-30 21:00:00 1.7 2012-03-30 22:00:00 0.4 2012-03-30 23:00:00 1.4 2012-03-31 00:00:00 1.5 2012-03-31 01:00:00 1.3 2012-03-31 02:00:00 1.3 2012-03-31 03:00:00 0.7 2012-03-31 04:00:00 -0.9 2012-03-31 05:00:00 -0.6 2012-03-31 06:00:00 -0.5 2012-03-31 07:00:00 -0.3 2012-03-31 08:00:00 0.7 2012-03-31 09:00:00 1.5 2012-03-31 10:00:00 2.9 2012-03-31 11:00:00 4.6 2012-03-31 12:00:00 6.4 2012-03-31 13:00:00 6.5 2012-03-31 14:00:00 7.7 2012-03-31 15:00:00 7.7 2012-03-31 16:00:00 8.4 2012-03-31 17:00:00 7.9 2012-03-31 18:00:00 7.0 2012-03-31 19:00:00 5.9 2012-03-31 20:00:00 4.4 2012-03-31 21:00:00 2.6 2012-03-31 22:00:00 2.7 2012-03-31 23:00:00 1.5 [744 rows x 1 columns]\u0026gt; So it looks like the time with the highest median temperature is 2pm. Neat.\n5.3 Getting the whole year of data Okay, so what if we want the data for the whole year? Ideally the API would just let us download that, but I couldn\u0026rsquo;t figure out a way to do that.\nFirst, let\u0026rsquo;s put our work from above into a function that gets the weather for a given month.\nI noticed that there\u0026rsquo;s an irritating bug where when I ask for January, it gives me data for the previous year, so we\u0026rsquo;ll fix that too. [no, really. You can check =)]\ndef download_weather_month(year, month): if month == 1: year += 1 url = url_template.format(year=year, month=month) weather_data = pd.read_csv(url, skiprows=15, index_col=\u0026#39;Date/Time\u0026#39;, parse_dates=True, header=True) weather_data = weather_data.dropna(axis=1) weather_data.columns = [col.replace(\u0026#39;\\xb0\u0026#39;, \u0026#39;\u0026#39;) for col in weather_data.columns] weather_data = weather_data.drop([\u0026#39;Year\u0026#39;, \u0026#39;Day\u0026#39;, \u0026#39;Month\u0026#39;, \u0026#39;Time\u0026#39;, \u0026#39;Data Quality\u0026#39;], axis=1) return weather_data We can test that this function does the right thing:\ndownload_weather_month(2012, 1)[:5] Output:\nNow we can get all the months at once. This will take a little while to run.\ndata_by_month = [download_weather_month(2012, i) for i in range(1, 13)] Once we have this, it\u0026rsquo;s easy to concatenate all the dataframes together into one big dataframe using pd.concat. And now we have the whole year\u0026rsquo;s data!\nweather_2012 = pd.concat(data_by_month) weather_2012 Output:\n5.4 Saving to a CSV It\u0026rsquo;s slow and unnecessary to download the data every time, so let\u0026rsquo;s save our dataframe for later use!\nweather_2012.to_csv(\u0026#39;weather_2012.csv\u0026#39;) And we\u0026rsquo;re done!\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter6/",
	"title": "Chapter 6 - String Operations",
	"tags": [],
	"description": "String Operations",
	"content": "%matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = (15, 3) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#39;sans-serif\u0026#39; We saw earlier that pandas is really good at dealing with dates. It is also amazing with strings! We\u0026rsquo;re going to go back to our weather data from Chapter 5, here.\nweather_2012 = pd.read_csv(\u0026#39;weather_2012.csv\u0026#39;, parse_dates=True, index_col=\u0026#39;Date/Time\u0026#39;) weather_2012[:5] Output:\n6.1 String operations You\u0026rsquo;ll see that the \u0026lsquo;Weather\u0026rsquo; column has a text description of the weather that was going on each hour. We\u0026rsquo;ll assume it\u0026rsquo;s snowing if the text description contains \u0026ldquo;Snow\u0026rdquo;.\npandas provides vectorized string functions, to make it easy to operate on columns containing text. There are some great examples in the documentation.\nweather_description = weather_2012[\u0026#39;Weather\u0026#39;] is_snowing = weather_description.str.contains(\u0026#39;Snow\u0026#39;) This gives us a binary vector, which is a bit hard to look at, so we\u0026rsquo;ll plot it.\n# Not super useful is_snowing[:5] Output:\nDate/Time 2012-01-01 00:00:00 False 2012-01-01 01:00:00 False 2012-01-01 02:00:00 False 2012-01-01 03:00:00 False 2012-01-01 04:00:00 False Name: Weather, dtype: bool # More useful! is_snowing.plot() Output:\n6.2 Use resampling to find the snowiest month If we wanted the median temperature each month, we could use the resample() method like this:\nweather_2012[\u0026#39;Temp (C)\u0026#39;].resample(\u0026#39;M\u0026#39;).apply(np.median).plot(kind=\u0026#39;bar\u0026#39;) Output:\nUnsurprisingly, July and August are the warmest.\nSo we can think of snowiness as being a bunch of 1s and 0s instead of Trues and Falses:\nis_snowing.astype(float)[:10] Output:\nDate/Time 2012-01-01 00:00:00 0 2012-01-01 01:00:00 0 2012-01-01 02:00:00 0 2012-01-01 03:00:00 0 2012-01-01 04:00:00 0 2012-01-01 05:00:00 0 2012-01-01 06:00:00 0 2012-01-01 07:00:00 0 2012-01-01 08:00:00 0 2012-01-01 09:00:00 0 Name: Weather, dtype: float64 and then use resample to find the percentage of time it was snowing each month\nis_snowing.astype(float).resample(\u0026#39;M\u0026#39;).apply(np.mean) Output:\nDate/Time 2012-01-31 0.240591 2012-02-29 0.162356 2012-03-31 0.087366 2012-04-30 0.015278 2012-05-31 0.000000 2012-06-30 0.000000 2012-07-31 0.000000 2012-08-31 0.000000 2012-09-30 0.000000 2012-10-31 0.000000 2012-11-30 0.038889 2012-12-31 0.251344 Freq: M, Name: Weather, dtype: float64 is_snowing.astype(float).resample(\u0026#39;M\u0026#39;).apply(np.mean).plot(kind=\u0026#39;bar\u0026#39;) Output:\nSo now we know! In 2012, December was the snowiest month. Also, this graph suggests something that I feel \u0026ndash; it starts snowing pretty abruptly in November, and then tapers off slowly and takes a long time to stop, with the last snow usually being in April or May.\n6.3 Plotting temperature and snowiness stats together We can also combine these two statistics (temperature, and snowiness) into one dataframe and plot them together:\ntemperature = weather_2012[\u0026#39;Temp (C)\u0026#39;].resample(\u0026#39;M\u0026#39;).apply(np.median) is_snowing = weather_2012[\u0026#39;Weather\u0026#39;].str.contains(\u0026#39;Snow\u0026#39;) snowiness = is_snowing.astype(float).resample(\u0026#39;M\u0026#39;).apply(np.mean) # Name the columns temperature.name = \u0026#34;Temperature\u0026#34; snowiness.name = \u0026#34;Snowiness\u0026#34; We\u0026rsquo;ll use concat again to combine the two statistics into a single dataframe.\nstats = pd.concat([temperature, snowiness], axis=1) stats Output:\nstats.plot(kind=\u0026#39;bar\u0026#39;) Output:\nUh, that didn\u0026rsquo;t work so well because the scale was wrong. We can do better by plotting them on two separate graphs:\nstats.plot(kind=\u0026#39;bar\u0026#39;, subplots=True, figsize=(15, 10)) Output:\n"
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter7/",
	"title": "Chapter 7 - Cleanup messy data",
	"tags": [],
	"description": "Cleanup messy data using Pandas",
	"content": "# The usual preamble import pandas as pd # Make the graphs a bit prettier, and bigger pd.set_option(\u0026#39;display.mpl_style\u0026#39;, \u0026#39;default\u0026#39;) figsize(15, 5) # Always display all the columns pd.set_option(\u0026#39;display.line_width\u0026#39;, 5000) pd.set_option(\u0026#39;display.max_columns\u0026#39;, 60) One of the main problems with messy data is: how do you know if it\u0026rsquo;s messy or not?\nWe\u0026rsquo;re going to use the NYC 311 service request dataset again here, since it\u0026rsquo;s big and a bit unwieldy.\nrequests = pd.read_csv(\u0026#39;311-service-requests.csv\u0026#39;) 7.1 How do we know if it\u0026rsquo;s messy? We\u0026rsquo;re going to look at a few columns here. I know already that there are some problems with the zip code, so let\u0026rsquo;s look at that first.\nTo get a sense for whether a column has problems, I usually use .unique() to look at all its values. If it\u0026rsquo;s a numeric column, I\u0026rsquo;ll instead plot a histogram to get a sense of the distribution.\nWhen we look at the unique values in \u0026ldquo;Incident Zip\u0026rdquo;, it quickly becomes clear that this is a mess.\nSome of the problems:\n Some have been parsed as strings, and some as floats There are nans Some of the zip codes are 29616-0759 or 83 There are some N/A values that pandas didn\u0026rsquo;t recognize, like \u0026lsquo;N/A\u0026rsquo; and \u0026lsquo;NO CLUE\u0026rsquo;  What we can do:\n Normalize \u0026lsquo;N/A\u0026rsquo; and \u0026lsquo;NO CLUE\u0026rsquo; into regular nan values Look at what\u0026rsquo;s up with the 83, and decide what to do Make everything strings  requests[\u0026#39;Incident Zip\u0026#39;].unique() Output:\narray([\u0026#39;11432\u0026#39;, \u0026#39;11378\u0026#39;, \u0026#39;10032\u0026#39;, \u0026#39;10023\u0026#39;, \u0026#39;10027\u0026#39;, \u0026#39;11372\u0026#39;, \u0026#39;11419\u0026#39;, \u0026#39;11417\u0026#39;, \u0026#39;10011\u0026#39;, \u0026#39;11225\u0026#39;, \u0026#39;11218\u0026#39;, \u0026#39;10003\u0026#39;, \u0026#39;10029\u0026#39;, \u0026#39;10466\u0026#39;, \u0026#39;11219\u0026#39;, \u0026#39;10025\u0026#39;, \u0026#39;10310\u0026#39;, \u0026#39;11236\u0026#39;, nan, \u0026#39;10033\u0026#39;, \u0026#39;11216\u0026#39;, \u0026#39;10016\u0026#39;, \u0026#39;10305\u0026#39;, \u0026#39;10312\u0026#39;, \u0026#39;10026\u0026#39;, \u0026#39;10309\u0026#39;, \u0026#39;10036\u0026#39;, \u0026#39;11433\u0026#39;, \u0026#39;11235\u0026#39;, \u0026#39;11213\u0026#39;, \u0026#39;11379\u0026#39;, \u0026#39;11101\u0026#39;, \u0026#39;10014\u0026#39;, \u0026#39;11231\u0026#39;, \u0026#39;11234\u0026#39;, \u0026#39;10457\u0026#39;, \u0026#39;10459\u0026#39;, \u0026#39;10465\u0026#39;, \u0026#39;11207\u0026#39;, \u0026#39;10002\u0026#39;, \u0026#39;10034\u0026#39;, \u0026#39;11233\u0026#39;, \u0026#39;10453\u0026#39;, \u0026#39;10456\u0026#39;, \u0026#39;10469\u0026#39;, \u0026#39;11374\u0026#39;, \u0026#39;11221\u0026#39;, \u0026#39;11421\u0026#39;, \u0026#39;11215\u0026#39;, \u0026#39;10007\u0026#39;, \u0026#39;10019\u0026#39;, \u0026#39;11205\u0026#39;, \u0026#39;11418\u0026#39;, \u0026#39;11369\u0026#39;, \u0026#39;11249\u0026#39;, \u0026#39;10005\u0026#39;, \u0026#39;10009\u0026#39;, \u0026#39;11211\u0026#39;, \u0026#39;11412\u0026#39;, \u0026#39;10458\u0026#39;, \u0026#39;11229\u0026#39;, \u0026#39;10065\u0026#39;, \u0026#39;10030\u0026#39;, \u0026#39;11222\u0026#39;, \u0026#39;10024\u0026#39;, \u0026#39;10013\u0026#39;, \u0026#39;11420\u0026#39;, \u0026#39;11365\u0026#39;, \u0026#39;10012\u0026#39;, \u0026#39;11214\u0026#39;, \u0026#39;11212\u0026#39;, \u0026#39;10022\u0026#39;, \u0026#39;11232\u0026#39;, \u0026#39;11040\u0026#39;, \u0026#39;11226\u0026#39;, \u0026#39;10281\u0026#39;, \u0026#39;11102\u0026#39;, \u0026#39;11208\u0026#39;, \u0026#39;10001\u0026#39;, \u0026#39;10472\u0026#39;, \u0026#39;11414\u0026#39;, \u0026#39;11223\u0026#39;, \u0026#39;10040\u0026#39;, \u0026#39;11220\u0026#39;, \u0026#39;11373\u0026#39;, \u0026#39;11203\u0026#39;, \u0026#39;11691\u0026#39;, \u0026#39;11356\u0026#39;, \u0026#39;10017\u0026#39;, \u0026#39;10452\u0026#39;, \u0026#39;10280\u0026#39;, \u0026#39;11217\u0026#39;, \u0026#39;10031\u0026#39;, \u0026#39;11201\u0026#39;, \u0026#39;11358\u0026#39;, \u0026#39;10128\u0026#39;, \u0026#39;11423\u0026#39;, \u0026#39;10039\u0026#39;, \u0026#39;10010\u0026#39;, \u0026#39;11209\u0026#39;, \u0026#39;10021\u0026#39;, \u0026#39;10037\u0026#39;, \u0026#39;11413\u0026#39;, \u0026#39;11375\u0026#39;, \u0026#39;11238\u0026#39;, \u0026#39;10473\u0026#39;, \u0026#39;11103\u0026#39;, \u0026#39;11354\u0026#39;, \u0026#39;11361\u0026#39;, \u0026#39;11106\u0026#39;, \u0026#39;11385\u0026#39;, \u0026#39;10463\u0026#39;, \u0026#39;10467\u0026#39;, \u0026#39;11204\u0026#39;, \u0026#39;11237\u0026#39;, \u0026#39;11377\u0026#39;, \u0026#39;11364\u0026#39;, \u0026#39;11434\u0026#39;, \u0026#39;11435\u0026#39;, \u0026#39;11210\u0026#39;, \u0026#39;11228\u0026#39;, \u0026#39;11368\u0026#39;, \u0026#39;11694\u0026#39;, \u0026#39;10464\u0026#39;, \u0026#39;11415\u0026#39;, \u0026#39;10314\u0026#39;, \u0026#39;10301\u0026#39;, \u0026#39;10018\u0026#39;, \u0026#39;10038\u0026#39;, \u0026#39;11105\u0026#39;, \u0026#39;11230\u0026#39;, \u0026#39;10468\u0026#39;, \u0026#39;11104\u0026#39;, \u0026#39;10471\u0026#39;, \u0026#39;11416\u0026#39;, \u0026#39;10075\u0026#39;, \u0026#39;11422\u0026#39;, \u0026#39;11355\u0026#39;, \u0026#39;10028\u0026#39;, \u0026#39;10462\u0026#39;, \u0026#39;10306\u0026#39;, \u0026#39;10461\u0026#39;, \u0026#39;11224\u0026#39;, \u0026#39;11429\u0026#39;, \u0026#39;10035\u0026#39;, \u0026#39;11366\u0026#39;, \u0026#39;11362\u0026#39;, \u0026#39;11206\u0026#39;, \u0026#39;10460\u0026#39;, \u0026#39;10304\u0026#39;, \u0026#39;11360\u0026#39;, \u0026#39;11411\u0026#39;, \u0026#39;10455\u0026#39;, \u0026#39;10475\u0026#39;, \u0026#39;10069\u0026#39;, \u0026#39;10303\u0026#39;, \u0026#39;10308\u0026#39;, \u0026#39;10302\u0026#39;, \u0026#39;11357\u0026#39;, \u0026#39;10470\u0026#39;, \u0026#39;11367\u0026#39;, \u0026#39;11370\u0026#39;, \u0026#39;10454\u0026#39;, \u0026#39;10451\u0026#39;, \u0026#39;11436\u0026#39;, \u0026#39;11426\u0026#39;, \u0026#39;10153\u0026#39;, \u0026#39;11004\u0026#39;, \u0026#39;11428\u0026#39;, \u0026#39;11427\u0026#39;, \u0026#39;11001\u0026#39;, \u0026#39;11363\u0026#39;, \u0026#39;10004\u0026#39;, \u0026#39;10474\u0026#39;, \u0026#39;11430\u0026#39;, \u0026#39;10000\u0026#39;, \u0026#39;10307\u0026#39;, \u0026#39;11239\u0026#39;, \u0026#39;10119\u0026#39;, \u0026#39;10006\u0026#39;, \u0026#39;10048\u0026#39;, \u0026#39;11697\u0026#39;, \u0026#39;11692\u0026#39;, \u0026#39;11693\u0026#39;, \u0026#39;10573\u0026#39;, \u0026#39;00083\u0026#39;, \u0026#39;N/A\u0026#39;, \u0026#39;11559\u0026#39;, \u0026#39;10020\u0026#39;, \u0026#39;77056\u0026#39;, \u0026#39;11776\u0026#39;, \u0026#39;70711\u0026#39;, \u0026#39;10282\u0026#39;, \u0026#39;11109\u0026#39;, \u0026#39;10044\u0026#39;, \u0026#39;02061\u0026#39;, \u0026#39;77092-2016\u0026#39;, \u0026#39;14225\u0026#39;, \u0026#39;55164-0737\u0026#39;, \u0026#39;19711\u0026#39;, \u0026#39;07306\u0026#39;, \u0026#39;000000\u0026#39;, \u0026#39;NO CLUE\u0026#39;, \u0026#39;90010\u0026#39;, \u0026#39;11747\u0026#39;, \u0026#39;23541\u0026#39;, \u0026#39;11788\u0026#39;, \u0026#39;07604\u0026#39;, 11203.0, 11217.0, 11418.0, 11385.0, 10461.0, 11236.0, 11223.0, 11205.0, 11218.0, 11207.0, 11234.0, 11215.0, 11420.0, 10463.0, 11213.0, 10014.0, 10011.0, 11421.0, 10029.0, 11433.0, 11691.0, 11358.0, 11368.0, 11435.0, 11105.0, 11101.0, 11419.0, 11355.0, 11377.0, 11210.0, 10040.0, 11208.0, 11228.0, 10022.0, 11412.0, 11209.0, 11211.0, 10018.0, 11106.0, 11411.0, 11369.0, 11237.0, 11230.0, 11364.0, 10472.0, 10304.0, 10075.0, 11249.0, 10032.0, 10016.0, 10308.0, 10306.0, 11225.0, 10006.0, 10009.0, 10033.0, 11104.0, 11204.0, 11415.0, 11103.0, 10025.0, 10473.0, 10469.0, 10466.0, 11231.0, 11226.0, 10455.0, 10019.0, 11220.0, 10459.0, 10002.0, 10039.0, 10026.0, 10456.0, 10468.0, 11222.0, 11214.0, 10470.0, 11373.0, 11367.0, 10302.0, 11235.0, 10128.0, 10467.0, 10458.0, 10475.0, 10474.0, 10453.0, 10462.0, 10301.0, 10065.0, 11221.0, 10031.0, 10460.0, 11233.0, 10457.0, 10027.0, 10003.0, 10038.0, 11212.0, 11206.0, 11434.0, 11361.0, 10036.0, 10005.0, 10024.0, 10035.0, 10030.0, 11694.0, 10454.0, 11238.0, 10464.0, 10452.0, 10037.0, 11219.0, 11216.0, 10028.0, 10451.0, 11229.0, 11422.0, 10010.0, 10023.0, 11692.0, 11374.0, 11416.0, 11429.0, 10314.0, 11375.0, 11354.0, 11378.0, 10303.0, 10034.0, 11423.0, 11372.0, 11379.0, 10007.0, 11201.0, 10001.0, 10310.0, 10012.0, 10309.0, 11232.0, 11224.0, 10305.0, 11693.0, 10021.0, 11432.0, 11356.0, 11436.0, 10312.0, 11413.0, 11102.0, 10013.0, 10471.0, 11417.0, 11365.0, 11004.0, 11366.0, 11362.0, 11370.0, 11357.0, 10112.0, 10017.0, 10307.0, 10465.0, 11426.0, 10280.0, 11430.0, 11109.0, 11414.0, 11788.0, 11563.0, 11580.0, 11427.0, 11428.0, 10000.0, 7087.0, 10282.0, 11360.0, 10020.0, 83.0, 10004.0, 11363.0, 11042.0, 11040.0, 7093.0, 10119.0, 11501.0, 92123.0, 11697.0, 0.0, 11575.0, 11239.0, 7109.0, 11797.0, 10069.0, \u0026#39;10803\u0026#39;, \u0026#39;11716\u0026#39;, \u0026#39;11722\u0026#39;, \u0026#39;11549-3650\u0026#39;, \u0026#39;10162\u0026#39;, \u0026#39;92123\u0026#39;, \u0026#39;23502\u0026#39;, \u0026#39;11518\u0026#39;, \u0026#39;07020\u0026#39;, \u0026#39;08807\u0026#39;, \u0026#39;11577\u0026#39;, \u0026#39;07114\u0026#39;, \u0026#39;11003\u0026#39;, \u0026#39;07201\u0026#39;, \u0026#39;11563\u0026#39;, \u0026#39;61702\u0026#39;, \u0026#39;10103\u0026#39;, \u0026#39;29616-0759\u0026#39;, \u0026#39;35209-3114\u0026#39;, \u0026#39;11520\u0026#39;, \u0026#39;11735\u0026#39;, \u0026#39;10129\u0026#39;, \u0026#39;11005\u0026#39;, \u0026#39;41042\u0026#39;, \u0026#39;11590\u0026#39;, 6901.0, 7208.0, 10048.0, 11530.0, 13221.0, 10954.0, 11001.0, 11735.0, 10103.0, 10044.0, 7114.0, 11111.0, 10107.0], dtype=object) 7.2 Fixing the nan values and string/float confusion We can pass a na_values option to pd.read_csv to clean this up a little bit. We can also specify that the type of Incident Zip is a string, not a float.\nna_values = [\u0026#39;NO CLUE\u0026#39;, \u0026#39;N/A\u0026#39;, \u0026#39;0\u0026#39;] requests = pd.read_csv(\u0026#39;../data/311-service-requests.csv\u0026#39;, na_values=na_values, dtype={\u0026#39;Incident Zip\u0026#39;: str}) requests[\u0026#39;Incident Zip\u0026#39;].unique() Output:\narray([\u0026#39;11432\u0026#39;, \u0026#39;11378\u0026#39;, \u0026#39;10032\u0026#39;, \u0026#39;10023\u0026#39;, \u0026#39;10027\u0026#39;, \u0026#39;11372\u0026#39;, \u0026#39;11419\u0026#39;, \u0026#39;11417\u0026#39;, \u0026#39;10011\u0026#39;, \u0026#39;11225\u0026#39;, \u0026#39;11218\u0026#39;, \u0026#39;10003\u0026#39;, \u0026#39;10029\u0026#39;, \u0026#39;10466\u0026#39;, \u0026#39;11219\u0026#39;, \u0026#39;10025\u0026#39;, \u0026#39;10310\u0026#39;, \u0026#39;11236\u0026#39;, nan, \u0026#39;10033\u0026#39;, \u0026#39;11216\u0026#39;, \u0026#39;10016\u0026#39;, \u0026#39;10305\u0026#39;, \u0026#39;10312\u0026#39;, \u0026#39;10026\u0026#39;, \u0026#39;10309\u0026#39;, \u0026#39;10036\u0026#39;, \u0026#39;11433\u0026#39;, \u0026#39;11235\u0026#39;, \u0026#39;11213\u0026#39;, \u0026#39;11379\u0026#39;, \u0026#39;11101\u0026#39;, \u0026#39;10014\u0026#39;, \u0026#39;11231\u0026#39;, \u0026#39;11234\u0026#39;, \u0026#39;10457\u0026#39;, \u0026#39;10459\u0026#39;, \u0026#39;10465\u0026#39;, \u0026#39;11207\u0026#39;, \u0026#39;10002\u0026#39;, \u0026#39;10034\u0026#39;, \u0026#39;11233\u0026#39;, \u0026#39;10453\u0026#39;, \u0026#39;10456\u0026#39;, \u0026#39;10469\u0026#39;, \u0026#39;11374\u0026#39;, \u0026#39;11221\u0026#39;, \u0026#39;11421\u0026#39;, \u0026#39;11215\u0026#39;, \u0026#39;10007\u0026#39;, \u0026#39;10019\u0026#39;, \u0026#39;11205\u0026#39;, \u0026#39;11418\u0026#39;, \u0026#39;11369\u0026#39;, \u0026#39;11249\u0026#39;, \u0026#39;10005\u0026#39;, \u0026#39;10009\u0026#39;, \u0026#39;11211\u0026#39;, \u0026#39;11412\u0026#39;, \u0026#39;10458\u0026#39;, \u0026#39;11229\u0026#39;, \u0026#39;10065\u0026#39;, \u0026#39;10030\u0026#39;, \u0026#39;11222\u0026#39;, \u0026#39;10024\u0026#39;, \u0026#39;10013\u0026#39;, \u0026#39;11420\u0026#39;, \u0026#39;11365\u0026#39;, \u0026#39;10012\u0026#39;, \u0026#39;11214\u0026#39;, \u0026#39;11212\u0026#39;, \u0026#39;10022\u0026#39;, \u0026#39;11232\u0026#39;, \u0026#39;11040\u0026#39;, \u0026#39;11226\u0026#39;, \u0026#39;10281\u0026#39;, \u0026#39;11102\u0026#39;, \u0026#39;11208\u0026#39;, \u0026#39;10001\u0026#39;, \u0026#39;10472\u0026#39;, \u0026#39;11414\u0026#39;, \u0026#39;11223\u0026#39;, \u0026#39;10040\u0026#39;, \u0026#39;11220\u0026#39;, \u0026#39;11373\u0026#39;, \u0026#39;11203\u0026#39;, \u0026#39;11691\u0026#39;, \u0026#39;11356\u0026#39;, \u0026#39;10017\u0026#39;, \u0026#39;10452\u0026#39;, \u0026#39;10280\u0026#39;, \u0026#39;11217\u0026#39;, \u0026#39;10031\u0026#39;, \u0026#39;11201\u0026#39;, \u0026#39;11358\u0026#39;, \u0026#39;10128\u0026#39;, \u0026#39;11423\u0026#39;, \u0026#39;10039\u0026#39;, \u0026#39;10010\u0026#39;, \u0026#39;11209\u0026#39;, \u0026#39;10021\u0026#39;, \u0026#39;10037\u0026#39;, \u0026#39;11413\u0026#39;, \u0026#39;11375\u0026#39;, \u0026#39;11238\u0026#39;, \u0026#39;10473\u0026#39;, \u0026#39;11103\u0026#39;, \u0026#39;11354\u0026#39;, \u0026#39;11361\u0026#39;, \u0026#39;11106\u0026#39;, \u0026#39;11385\u0026#39;, \u0026#39;10463\u0026#39;, \u0026#39;10467\u0026#39;, \u0026#39;11204\u0026#39;, \u0026#39;11237\u0026#39;, \u0026#39;11377\u0026#39;, \u0026#39;11364\u0026#39;, \u0026#39;11434\u0026#39;, \u0026#39;11435\u0026#39;, \u0026#39;11210\u0026#39;, \u0026#39;11228\u0026#39;, \u0026#39;11368\u0026#39;, \u0026#39;11694\u0026#39;, \u0026#39;10464\u0026#39;, \u0026#39;11415\u0026#39;, \u0026#39;10314\u0026#39;, \u0026#39;10301\u0026#39;, \u0026#39;10018\u0026#39;, \u0026#39;10038\u0026#39;, \u0026#39;11105\u0026#39;, \u0026#39;11230\u0026#39;, \u0026#39;10468\u0026#39;, \u0026#39;11104\u0026#39;, \u0026#39;10471\u0026#39;, \u0026#39;11416\u0026#39;, \u0026#39;10075\u0026#39;, \u0026#39;11422\u0026#39;, \u0026#39;11355\u0026#39;, \u0026#39;10028\u0026#39;, \u0026#39;10462\u0026#39;, \u0026#39;10306\u0026#39;, \u0026#39;10461\u0026#39;, \u0026#39;11224\u0026#39;, \u0026#39;11429\u0026#39;, \u0026#39;10035\u0026#39;, \u0026#39;11366\u0026#39;, \u0026#39;11362\u0026#39;, \u0026#39;11206\u0026#39;, \u0026#39;10460\u0026#39;, \u0026#39;10304\u0026#39;, \u0026#39;11360\u0026#39;, \u0026#39;11411\u0026#39;, \u0026#39;10455\u0026#39;, \u0026#39;10475\u0026#39;, \u0026#39;10069\u0026#39;, \u0026#39;10303\u0026#39;, \u0026#39;10308\u0026#39;, \u0026#39;10302\u0026#39;, \u0026#39;11357\u0026#39;, \u0026#39;10470\u0026#39;, \u0026#39;11367\u0026#39;, \u0026#39;11370\u0026#39;, \u0026#39;10454\u0026#39;, \u0026#39;10451\u0026#39;, \u0026#39;11436\u0026#39;, \u0026#39;11426\u0026#39;, \u0026#39;10153\u0026#39;, \u0026#39;11004\u0026#39;, \u0026#39;11428\u0026#39;, \u0026#39;11427\u0026#39;, \u0026#39;11001\u0026#39;, \u0026#39;11363\u0026#39;, \u0026#39;10004\u0026#39;, \u0026#39;10474\u0026#39;, \u0026#39;11430\u0026#39;, \u0026#39;10000\u0026#39;, \u0026#39;10307\u0026#39;, \u0026#39;11239\u0026#39;, \u0026#39;10119\u0026#39;, \u0026#39;10006\u0026#39;, \u0026#39;10048\u0026#39;, \u0026#39;11697\u0026#39;, \u0026#39;11692\u0026#39;, \u0026#39;11693\u0026#39;, \u0026#39;10573\u0026#39;, \u0026#39;00083\u0026#39;, \u0026#39;11559\u0026#39;, \u0026#39;10020\u0026#39;, \u0026#39;77056\u0026#39;, \u0026#39;11776\u0026#39;, \u0026#39;70711\u0026#39;, \u0026#39;10282\u0026#39;, \u0026#39;11109\u0026#39;, \u0026#39;10044\u0026#39;, \u0026#39;02061\u0026#39;, \u0026#39;77092-2016\u0026#39;, \u0026#39;14225\u0026#39;, \u0026#39;55164-0737\u0026#39;, \u0026#39;19711\u0026#39;, \u0026#39;07306\u0026#39;, \u0026#39;000000\u0026#39;, \u0026#39;90010\u0026#39;, \u0026#39;11747\u0026#39;, \u0026#39;23541\u0026#39;, \u0026#39;11788\u0026#39;, \u0026#39;07604\u0026#39;, \u0026#39;10112\u0026#39;, \u0026#39;11563\u0026#39;, \u0026#39;11580\u0026#39;, \u0026#39;07087\u0026#39;, \u0026#39;11042\u0026#39;, \u0026#39;07093\u0026#39;, \u0026#39;11501\u0026#39;, \u0026#39;92123\u0026#39;, \u0026#39;00000\u0026#39;, \u0026#39;11575\u0026#39;, \u0026#39;07109\u0026#39;, \u0026#39;11797\u0026#39;, \u0026#39;10803\u0026#39;, \u0026#39;11716\u0026#39;, \u0026#39;11722\u0026#39;, \u0026#39;11549-3650\u0026#39;, \u0026#39;10162\u0026#39;, \u0026#39;23502\u0026#39;, \u0026#39;11518\u0026#39;, \u0026#39;07020\u0026#39;, \u0026#39;08807\u0026#39;, \u0026#39;11577\u0026#39;, \u0026#39;07114\u0026#39;, \u0026#39;11003\u0026#39;, \u0026#39;07201\u0026#39;, \u0026#39;61702\u0026#39;, \u0026#39;10103\u0026#39;, \u0026#39;29616-0759\u0026#39;, \u0026#39;35209-3114\u0026#39;, \u0026#39;11520\u0026#39;, \u0026#39;11735\u0026#39;, \u0026#39;10129\u0026#39;, \u0026#39;11005\u0026#39;, \u0026#39;41042\u0026#39;, \u0026#39;11590\u0026#39;, \u0026#39;06901\u0026#39;, \u0026#39;07208\u0026#39;, \u0026#39;11530\u0026#39;, \u0026#39;13221\u0026#39;, \u0026#39;10954\u0026#39;, \u0026#39;11111\u0026#39;, \u0026#39;10107\u0026#39;], dtype=object) 7.3 What\u0026rsquo;s up with the dashes? rows_with_dashes = requests[\u0026#39;Incident Zip\u0026#39;].str.contains(\u0026#39;-\u0026#39;).fillna(False) len(requests[rows_with_dashes]) Output:\n5 requests[rows_with_dashes] Output:\nI thought these were missing data and originally deleted them like this:\nrequests[\u0026#39;Incident Zip\u0026#39;][rows_with_dashes] = np.nan But then my friend pointed out that 9-digit zip codes are normal. Let\u0026rsquo;s look at all the zip codes with more than 5 digits, make sure they\u0026rsquo;re okay, and then truncate them.\nlong_zip_codes = requests[\u0026#39;Incident Zip\u0026#39;].str.len() \u0026gt; 5 requests[\u0026#39;Incident Zip\u0026#39;][long_zip_codes].unique() Output:\narray([\u0026#39;77092-2016\u0026#39;, \u0026#39;55164-0737\u0026#39;, \u0026#39;000000\u0026#39;, \u0026#39;11549-3650\u0026#39;, \u0026#39;29616-0759\u0026#39;, \u0026#39;35209-3114\u0026#39;], dtype=object) Those all look okay to truncate to me.\nrequests[\u0026#39;Incident Zip\u0026#39;] = requests[\u0026#39;Incident Zip\u0026#39;].str.slice(0, 5) Done.\nEarlier I thought 00083 was a broken zip code, but turns out Central Park\u0026rsquo;s zip code 00083! Shows what I know. I\u0026rsquo;m still concerned about the 00000 zip codes, though: let\u0026rsquo;s look at that.\nrequests[requests[\u0026#39;Incident Zip\u0026#39;] == \u0026#39;00000\u0026#39;] Output:\nThis looks bad to me. Let\u0026rsquo;s set these to nan.\nzero_zips = requests[\u0026#39;Incident Zip\u0026#39;] == \u0026#39;00000\u0026#39; requests[\u0026#39;Incident Zip\u0026#39;][zero_zips] = np.nan Great. Let\u0026rsquo;s see where we are now:\nunique_zips = requests[\u0026#39;Incident Zip\u0026#39;].unique() unique_zips.sort() unique_zips Output:\narray([nan, \u0026#39;00083\u0026#39;, \u0026#39;02061\u0026#39;, \u0026#39;06901\u0026#39;, \u0026#39;07020\u0026#39;, \u0026#39;07087\u0026#39;, \u0026#39;07093\u0026#39;, \u0026#39;07109\u0026#39;, \u0026#39;07114\u0026#39;, \u0026#39;07201\u0026#39;, \u0026#39;07208\u0026#39;, \u0026#39;07306\u0026#39;, \u0026#39;07604\u0026#39;, \u0026#39;08807\u0026#39;, \u0026#39;10000\u0026#39;, \u0026#39;10001\u0026#39;, \u0026#39;10002\u0026#39;, \u0026#39;10003\u0026#39;, \u0026#39;10004\u0026#39;, \u0026#39;10005\u0026#39;, \u0026#39;10006\u0026#39;, \u0026#39;10007\u0026#39;, \u0026#39;10009\u0026#39;, \u0026#39;10010\u0026#39;, \u0026#39;10011\u0026#39;, \u0026#39;10012\u0026#39;, \u0026#39;10013\u0026#39;, \u0026#39;10014\u0026#39;, \u0026#39;10016\u0026#39;, \u0026#39;10017\u0026#39;, \u0026#39;10018\u0026#39;, \u0026#39;10019\u0026#39;, \u0026#39;10020\u0026#39;, \u0026#39;10021\u0026#39;, \u0026#39;10022\u0026#39;, \u0026#39;10023\u0026#39;, \u0026#39;10024\u0026#39;, \u0026#39;10025\u0026#39;, \u0026#39;10026\u0026#39;, \u0026#39;10027\u0026#39;, \u0026#39;10028\u0026#39;, \u0026#39;10029\u0026#39;, \u0026#39;10030\u0026#39;, \u0026#39;10031\u0026#39;, \u0026#39;10032\u0026#39;, \u0026#39;10033\u0026#39;, \u0026#39;10034\u0026#39;, \u0026#39;10035\u0026#39;, \u0026#39;10036\u0026#39;, \u0026#39;10037\u0026#39;, \u0026#39;10038\u0026#39;, \u0026#39;10039\u0026#39;, \u0026#39;10040\u0026#39;, \u0026#39;10044\u0026#39;, \u0026#39;10048\u0026#39;, \u0026#39;10065\u0026#39;, \u0026#39;10069\u0026#39;, \u0026#39;10075\u0026#39;, \u0026#39;10103\u0026#39;, \u0026#39;10107\u0026#39;, \u0026#39;10112\u0026#39;, \u0026#39;10119\u0026#39;, \u0026#39;10128\u0026#39;, \u0026#39;10129\u0026#39;, \u0026#39;10153\u0026#39;, \u0026#39;10162\u0026#39;, \u0026#39;10280\u0026#39;, \u0026#39;10281\u0026#39;, \u0026#39;10282\u0026#39;, \u0026#39;10301\u0026#39;, \u0026#39;10302\u0026#39;, \u0026#39;10303\u0026#39;, \u0026#39;10304\u0026#39;, \u0026#39;10305\u0026#39;, \u0026#39;10306\u0026#39;, \u0026#39;10307\u0026#39;, \u0026#39;10308\u0026#39;, \u0026#39;10309\u0026#39;, \u0026#39;10310\u0026#39;, \u0026#39;10312\u0026#39;, \u0026#39;10314\u0026#39;, \u0026#39;10451\u0026#39;, \u0026#39;10452\u0026#39;, \u0026#39;10453\u0026#39;, \u0026#39;10454\u0026#39;, \u0026#39;10455\u0026#39;, \u0026#39;10456\u0026#39;, \u0026#39;10457\u0026#39;, \u0026#39;10458\u0026#39;, \u0026#39;10459\u0026#39;, \u0026#39;10460\u0026#39;, \u0026#39;10461\u0026#39;, \u0026#39;10462\u0026#39;, \u0026#39;10463\u0026#39;, \u0026#39;10464\u0026#39;, \u0026#39;10465\u0026#39;, \u0026#39;10466\u0026#39;, \u0026#39;10467\u0026#39;, \u0026#39;10468\u0026#39;, \u0026#39;10469\u0026#39;, \u0026#39;10470\u0026#39;, \u0026#39;10471\u0026#39;, \u0026#39;10472\u0026#39;, \u0026#39;10473\u0026#39;, \u0026#39;10474\u0026#39;, \u0026#39;10475\u0026#39;, \u0026#39;10573\u0026#39;, \u0026#39;10803\u0026#39;, \u0026#39;10954\u0026#39;, \u0026#39;11001\u0026#39;, \u0026#39;11003\u0026#39;, \u0026#39;11004\u0026#39;, \u0026#39;11005\u0026#39;, \u0026#39;11040\u0026#39;, \u0026#39;11042\u0026#39;, \u0026#39;11101\u0026#39;, \u0026#39;11102\u0026#39;, \u0026#39;11103\u0026#39;, \u0026#39;11104\u0026#39;, \u0026#39;11105\u0026#39;, \u0026#39;11106\u0026#39;, \u0026#39;11109\u0026#39;, \u0026#39;11111\u0026#39;, \u0026#39;11201\u0026#39;, \u0026#39;11203\u0026#39;, \u0026#39;11204\u0026#39;, \u0026#39;11205\u0026#39;, \u0026#39;11206\u0026#39;, \u0026#39;11207\u0026#39;, \u0026#39;11208\u0026#39;, \u0026#39;11209\u0026#39;, \u0026#39;11210\u0026#39;, \u0026#39;11211\u0026#39;, \u0026#39;11212\u0026#39;, \u0026#39;11213\u0026#39;, \u0026#39;11214\u0026#39;, \u0026#39;11215\u0026#39;, \u0026#39;11216\u0026#39;, \u0026#39;11217\u0026#39;, \u0026#39;11218\u0026#39;, \u0026#39;11219\u0026#39;, \u0026#39;11220\u0026#39;, \u0026#39;11221\u0026#39;, \u0026#39;11222\u0026#39;, \u0026#39;11223\u0026#39;, \u0026#39;11224\u0026#39;, \u0026#39;11225\u0026#39;, \u0026#39;11226\u0026#39;, \u0026#39;11228\u0026#39;, \u0026#39;11229\u0026#39;, \u0026#39;11230\u0026#39;, \u0026#39;11231\u0026#39;, \u0026#39;11232\u0026#39;, \u0026#39;11233\u0026#39;, \u0026#39;11234\u0026#39;, \u0026#39;11235\u0026#39;, \u0026#39;11236\u0026#39;, \u0026#39;11237\u0026#39;, \u0026#39;11238\u0026#39;, \u0026#39;11239\u0026#39;, \u0026#39;11249\u0026#39;, \u0026#39;11354\u0026#39;, \u0026#39;11355\u0026#39;, \u0026#39;11356\u0026#39;, \u0026#39;11357\u0026#39;, \u0026#39;11358\u0026#39;, \u0026#39;11360\u0026#39;, \u0026#39;11361\u0026#39;, \u0026#39;11362\u0026#39;, \u0026#39;11363\u0026#39;, \u0026#39;11364\u0026#39;, \u0026#39;11365\u0026#39;, \u0026#39;11366\u0026#39;, \u0026#39;11367\u0026#39;, \u0026#39;11368\u0026#39;, \u0026#39;11369\u0026#39;, \u0026#39;11370\u0026#39;, \u0026#39;11372\u0026#39;, \u0026#39;11373\u0026#39;, \u0026#39;11374\u0026#39;, \u0026#39;11375\u0026#39;, \u0026#39;11377\u0026#39;, \u0026#39;11378\u0026#39;, \u0026#39;11379\u0026#39;, \u0026#39;11385\u0026#39;, \u0026#39;11411\u0026#39;, \u0026#39;11412\u0026#39;, \u0026#39;11413\u0026#39;, \u0026#39;11414\u0026#39;, \u0026#39;11415\u0026#39;, \u0026#39;11416\u0026#39;, \u0026#39;11417\u0026#39;, \u0026#39;11418\u0026#39;, \u0026#39;11419\u0026#39;, \u0026#39;11420\u0026#39;, \u0026#39;11421\u0026#39;, \u0026#39;11422\u0026#39;, \u0026#39;11423\u0026#39;, \u0026#39;11426\u0026#39;, \u0026#39;11427\u0026#39;, \u0026#39;11428\u0026#39;, \u0026#39;11429\u0026#39;, \u0026#39;11430\u0026#39;, \u0026#39;11432\u0026#39;, \u0026#39;11433\u0026#39;, \u0026#39;11434\u0026#39;, \u0026#39;11435\u0026#39;, \u0026#39;11436\u0026#39;, \u0026#39;11501\u0026#39;, \u0026#39;11518\u0026#39;, \u0026#39;11520\u0026#39;, \u0026#39;11530\u0026#39;, \u0026#39;11549\u0026#39;, \u0026#39;11559\u0026#39;, \u0026#39;11563\u0026#39;, \u0026#39;11575\u0026#39;, \u0026#39;11577\u0026#39;, \u0026#39;11580\u0026#39;, \u0026#39;11590\u0026#39;, \u0026#39;11691\u0026#39;, \u0026#39;11692\u0026#39;, \u0026#39;11693\u0026#39;, \u0026#39;11694\u0026#39;, \u0026#39;11697\u0026#39;, \u0026#39;11716\u0026#39;, \u0026#39;11722\u0026#39;, \u0026#39;11735\u0026#39;, \u0026#39;11747\u0026#39;, \u0026#39;11776\u0026#39;, \u0026#39;11788\u0026#39;, \u0026#39;11797\u0026#39;, \u0026#39;13221\u0026#39;, \u0026#39;14225\u0026#39;, \u0026#39;19711\u0026#39;, \u0026#39;23502\u0026#39;, \u0026#39;23541\u0026#39;, \u0026#39;29616\u0026#39;, \u0026#39;35209\u0026#39;, \u0026#39;41042\u0026#39;, \u0026#39;55164\u0026#39;, \u0026#39;61702\u0026#39;, \u0026#39;70711\u0026#39;, \u0026#39;77056\u0026#39;, \u0026#39;77092\u0026#39;, \u0026#39;90010\u0026#39;, \u0026#39;92123\u0026#39;], dtype=object) Amazing! This is much cleaner. There\u0026rsquo;s something a bit weird here, though \u0026ndash; I looked up 77056 on Google maps, and that\u0026rsquo;s in Texas.\nLet\u0026rsquo;s take a closer look:\nzips = requests[\u0026#39;Incident Zip\u0026#39;] # Let\u0026#39;s say the zips starting with \u0026#39;0\u0026#39; and \u0026#39;1\u0026#39; are okay, for now. (this isn\u0026#39;t actually true -- 13221 is in Syracuse, and why?) is_close = zips.str.startswith(\u0026#39;0\u0026#39;) | zips.str.startswith(\u0026#39;1\u0026#39;) # There are a bunch of NaNs, but we\u0026#39;re not interested in them right now, so we\u0026#39;ll say they\u0026#39;re True is_far = ~(is_close.fillna(True).astype(bool)) zips[is_far] Output:\n12102 77056 13450 70711 29136 77092 30939 55164 44008 90010 47048 23541 57636 92123 71001 92123 71834 23502 80573 61702 85821 29616 89304 35209 94201 41042 Name: Incident Zip, dtype: object requests[is_far][[\u0026#39;Incident Zip\u0026#39;, \u0026#39;Descriptor\u0026#39;, \u0026#39;City\u0026#39;]].sort(\u0026#39;Incident Zip\u0026#39;) Output:\nOkay, there really are requests coming from LA and Houston! Good to know. Filtering by zip code is probably a bad way to handle this \u0026ndash; we should really be looking at the city instead.\nrequests[\u0026#39;City\u0026#39;].str.upper().value_counts() Output:\nBROOKLYN 31662 NEW YORK 22664 BRONX 18438 STATEN ISLAND 4766 JAMAICA 2246 FLUSHING 1803 ASTORIA 1568 RIDGEWOOD 1073 CORONA 707 OZONE PARK 693 LONG ISLAND CITY 678 FAR ROCKAWAY 652 ELMHURST 647 WOODSIDE 609 EAST ELMHURST 562 ... MELVILLE 1 PORT JEFFERSON STATION 1 NORWELL 1 EAST ROCKAWAY 1 BIRMINGHAM 1 ROSLYN 1 LOS ANGELES 1 MINEOLA 1 JERSEY CITY 1 ST. PAUL 1 CLIFTON 1 COL.ANVURES 1 EDGEWATER 1 ROSELYN 1 CENTRAL ISLIP 1 Length: 100, dtype: int64 It looks like these are legitimate complaints, so we\u0026rsquo;ll just leave them alone.\n7.4 Putting it together Here\u0026rsquo;s what we ended up doing to clean up our zip codes, all together:\nna_values = [\u0026#39;NO CLUE\u0026#39;, \u0026#39;N/A\u0026#39;, \u0026#39;0\u0026#39;] requests = pd.read_csv(\u0026#39;311-service-requests.csv\u0026#39;, na_values=na_values, dtype={\u0026#39;Incident Zip\u0026#39;: str}) def fix_zip_codes(zips): # Truncate everything to length 5  zips = zips.str.slice(0, 5) # Set 00000 zip codes to nan zero_zips = zips == \u0026#39;00000\u0026#39; zips[zero_zips] = np.nan return zips requests[\u0026#39;Incident Zip\u0026#39;] = fix_zip_codes(requests[\u0026#39;Incident Zip\u0026#39;]) requests[\u0026#39;Incident Zip\u0026#39;].unique() Output:\narray([\u0026#39;11432\u0026#39;, \u0026#39;11378\u0026#39;, \u0026#39;10032\u0026#39;, \u0026#39;10023\u0026#39;, \u0026#39;10027\u0026#39;, \u0026#39;11372\u0026#39;, \u0026#39;11419\u0026#39;, \u0026#39;11417\u0026#39;, \u0026#39;10011\u0026#39;, \u0026#39;11225\u0026#39;, \u0026#39;11218\u0026#39;, \u0026#39;10003\u0026#39;, \u0026#39;10029\u0026#39;, \u0026#39;10466\u0026#39;, \u0026#39;11219\u0026#39;, \u0026#39;10025\u0026#39;, \u0026#39;10310\u0026#39;, \u0026#39;11236\u0026#39;, nan, \u0026#39;10033\u0026#39;, \u0026#39;11216\u0026#39;, \u0026#39;10016\u0026#39;, \u0026#39;10305\u0026#39;, \u0026#39;10312\u0026#39;, \u0026#39;10026\u0026#39;, \u0026#39;10309\u0026#39;, \u0026#39;10036\u0026#39;, \u0026#39;11433\u0026#39;, \u0026#39;11235\u0026#39;, \u0026#39;11213\u0026#39;, \u0026#39;11379\u0026#39;, \u0026#39;11101\u0026#39;, \u0026#39;10014\u0026#39;, \u0026#39;11231\u0026#39;, \u0026#39;11234\u0026#39;, \u0026#39;10457\u0026#39;, \u0026#39;10459\u0026#39;, \u0026#39;10465\u0026#39;, \u0026#39;11207\u0026#39;, \u0026#39;10002\u0026#39;, \u0026#39;10034\u0026#39;, \u0026#39;11233\u0026#39;, \u0026#39;10453\u0026#39;, \u0026#39;10456\u0026#39;, \u0026#39;10469\u0026#39;, \u0026#39;11374\u0026#39;, \u0026#39;11221\u0026#39;, \u0026#39;11421\u0026#39;, \u0026#39;11215\u0026#39;, \u0026#39;10007\u0026#39;, \u0026#39;10019\u0026#39;, \u0026#39;11205\u0026#39;, \u0026#39;11418\u0026#39;, \u0026#39;11369\u0026#39;, \u0026#39;11249\u0026#39;, \u0026#39;10005\u0026#39;, \u0026#39;10009\u0026#39;, \u0026#39;11211\u0026#39;, \u0026#39;11412\u0026#39;, \u0026#39;10458\u0026#39;, \u0026#39;11229\u0026#39;, \u0026#39;10065\u0026#39;, \u0026#39;10030\u0026#39;, \u0026#39;11222\u0026#39;, \u0026#39;10024\u0026#39;, \u0026#39;10013\u0026#39;, \u0026#39;11420\u0026#39;, \u0026#39;11365\u0026#39;, \u0026#39;10012\u0026#39;, \u0026#39;11214\u0026#39;, \u0026#39;11212\u0026#39;, \u0026#39;10022\u0026#39;, \u0026#39;11232\u0026#39;, \u0026#39;11040\u0026#39;, \u0026#39;11226\u0026#39;, \u0026#39;10281\u0026#39;, \u0026#39;11102\u0026#39;, \u0026#39;11208\u0026#39;, \u0026#39;10001\u0026#39;, \u0026#39;10472\u0026#39;, \u0026#39;11414\u0026#39;, \u0026#39;11223\u0026#39;, \u0026#39;10040\u0026#39;, \u0026#39;11220\u0026#39;, \u0026#39;11373\u0026#39;, \u0026#39;11203\u0026#39;, \u0026#39;11691\u0026#39;, \u0026#39;11356\u0026#39;, \u0026#39;10017\u0026#39;, \u0026#39;10452\u0026#39;, \u0026#39;10280\u0026#39;, \u0026#39;11217\u0026#39;, \u0026#39;10031\u0026#39;, \u0026#39;11201\u0026#39;, \u0026#39;11358\u0026#39;, \u0026#39;10128\u0026#39;, \u0026#39;11423\u0026#39;, \u0026#39;10039\u0026#39;, \u0026#39;10010\u0026#39;, \u0026#39;11209\u0026#39;, \u0026#39;10021\u0026#39;, \u0026#39;10037\u0026#39;, \u0026#39;11413\u0026#39;, \u0026#39;11375\u0026#39;, \u0026#39;11238\u0026#39;, \u0026#39;10473\u0026#39;, \u0026#39;11103\u0026#39;, \u0026#39;11354\u0026#39;, \u0026#39;11361\u0026#39;, \u0026#39;11106\u0026#39;, \u0026#39;11385\u0026#39;, \u0026#39;10463\u0026#39;, \u0026#39;10467\u0026#39;, \u0026#39;11204\u0026#39;, \u0026#39;11237\u0026#39;, \u0026#39;11377\u0026#39;, \u0026#39;11364\u0026#39;, \u0026#39;11434\u0026#39;, \u0026#39;11435\u0026#39;, \u0026#39;11210\u0026#39;, \u0026#39;11228\u0026#39;, \u0026#39;11368\u0026#39;, \u0026#39;11694\u0026#39;, \u0026#39;10464\u0026#39;, \u0026#39;11415\u0026#39;, \u0026#39;10314\u0026#39;, \u0026#39;10301\u0026#39;, \u0026#39;10018\u0026#39;, \u0026#39;10038\u0026#39;, \u0026#39;11105\u0026#39;, \u0026#39;11230\u0026#39;, \u0026#39;10468\u0026#39;, \u0026#39;11104\u0026#39;, \u0026#39;10471\u0026#39;, \u0026#39;11416\u0026#39;, \u0026#39;10075\u0026#39;, \u0026#39;11422\u0026#39;, \u0026#39;11355\u0026#39;, \u0026#39;10028\u0026#39;, \u0026#39;10462\u0026#39;, \u0026#39;10306\u0026#39;, \u0026#39;10461\u0026#39;, \u0026#39;11224\u0026#39;, \u0026#39;11429\u0026#39;, \u0026#39;10035\u0026#39;, \u0026#39;11366\u0026#39;, \u0026#39;11362\u0026#39;, \u0026#39;11206\u0026#39;, \u0026#39;10460\u0026#39;, \u0026#39;10304\u0026#39;, \u0026#39;11360\u0026#39;, \u0026#39;11411\u0026#39;, \u0026#39;10455\u0026#39;, \u0026#39;10475\u0026#39;, \u0026#39;10069\u0026#39;, \u0026#39;10303\u0026#39;, \u0026#39;10308\u0026#39;, \u0026#39;10302\u0026#39;, \u0026#39;11357\u0026#39;, \u0026#39;10470\u0026#39;, \u0026#39;11367\u0026#39;, \u0026#39;11370\u0026#39;, \u0026#39;10454\u0026#39;, \u0026#39;10451\u0026#39;, \u0026#39;11436\u0026#39;, \u0026#39;11426\u0026#39;, \u0026#39;10153\u0026#39;, \u0026#39;11004\u0026#39;, \u0026#39;11428\u0026#39;, \u0026#39;11427\u0026#39;, \u0026#39;11001\u0026#39;, \u0026#39;11363\u0026#39;, \u0026#39;10004\u0026#39;, \u0026#39;10474\u0026#39;, \u0026#39;11430\u0026#39;, \u0026#39;10000\u0026#39;, \u0026#39;10307\u0026#39;, \u0026#39;11239\u0026#39;, \u0026#39;10119\u0026#39;, \u0026#39;10006\u0026#39;, \u0026#39;10048\u0026#39;, \u0026#39;11697\u0026#39;, \u0026#39;11692\u0026#39;, \u0026#39;11693\u0026#39;, \u0026#39;10573\u0026#39;, \u0026#39;00083\u0026#39;, \u0026#39;11559\u0026#39;, \u0026#39;10020\u0026#39;, \u0026#39;77056\u0026#39;, \u0026#39;11776\u0026#39;, \u0026#39;70711\u0026#39;, \u0026#39;10282\u0026#39;, \u0026#39;11109\u0026#39;, \u0026#39;10044\u0026#39;, \u0026#39;02061\u0026#39;, \u0026#39;77092\u0026#39;, \u0026#39;14225\u0026#39;, \u0026#39;55164\u0026#39;, \u0026#39;19711\u0026#39;, \u0026#39;07306\u0026#39;, \u0026#39;90010\u0026#39;, \u0026#39;11747\u0026#39;, \u0026#39;23541\u0026#39;, \u0026#39;11788\u0026#39;, \u0026#39;07604\u0026#39;, \u0026#39;10112\u0026#39;, \u0026#39;11563\u0026#39;, \u0026#39;11580\u0026#39;, \u0026#39;07087\u0026#39;, \u0026#39;11042\u0026#39;, \u0026#39;07093\u0026#39;, \u0026#39;11501\u0026#39;, \u0026#39;92123\u0026#39;, \u0026#39;11575\u0026#39;, \u0026#39;07109\u0026#39;, \u0026#39;11797\u0026#39;, \u0026#39;10803\u0026#39;, \u0026#39;11716\u0026#39;, \u0026#39;11722\u0026#39;, \u0026#39;11549\u0026#39;, \u0026#39;10162\u0026#39;, \u0026#39;23502\u0026#39;, \u0026#39;11518\u0026#39;, \u0026#39;07020\u0026#39;, \u0026#39;08807\u0026#39;, \u0026#39;11577\u0026#39;, \u0026#39;07114\u0026#39;, \u0026#39;11003\u0026#39;, \u0026#39;07201\u0026#39;, \u0026#39;61702\u0026#39;, \u0026#39;10103\u0026#39;, \u0026#39;29616\u0026#39;, \u0026#39;35209\u0026#39;, \u0026#39;11520\u0026#39;, \u0026#39;11735\u0026#39;, \u0026#39;10129\u0026#39;, \u0026#39;11005\u0026#39;, \u0026#39;41042\u0026#39;, \u0026#39;11590\u0026#39;, \u0026#39;06901\u0026#39;, \u0026#39;07208\u0026#39;, \u0026#39;11530\u0026#39;, \u0026#39;13221\u0026#39;, \u0026#39;10954\u0026#39;, \u0026#39;11111\u0026#39;, \u0026#39;10107\u0026#39;], dtype=object) "
},
{
	"uri": "http://tutswiki.com/pandas-cookbook/chapter8/",
	"title": "Chapter 8 - Parsing Unix timestamps",
	"tags": [],
	"description": "Parsing Unix timestamps",
	"content": "8.1 Parsing Unix timestamps It\u0026rsquo;s not obvious how to deal with Unix timestamps in pandas \u0026ndash; it took me quite a while to figure this out. The file we\u0026rsquo;re using here is a popularity-contest file I found on my system at /var/log/popularity-contest.\nHere\u0026rsquo;s an explanation of how this file works.\nI\u0026rsquo;m going to hope that nothing in it is sensitive :)\nimport pandas as pd # Read it, and remove the last row popcon = pd.read_csv(\u0026#39;popularity-contest\u0026#39;, sep=\u0026#39; \u0026#39;, )[:-1] popcon.columns = [\u0026#39;atime\u0026#39;, \u0026#39;ctime\u0026#39;, \u0026#39;package-name\u0026#39;, \u0026#39;mru-program\u0026#39;, \u0026#39;tag\u0026#39;] popcon[:5] The colums are the access time, created time, package name, recently used program, and a tag\nOutput:\nThe magical part about parsing timestamps in pandas is that numpy datetimes are already stored as Unix timestamps. So all we need to do is tell pandas that these integers are actually datetimes \u0026ndash; it doesn\u0026rsquo;t need to do any conversion at all.\nWe need to convert these to ints to start:\npopcon[\u0026#39;atime\u0026#39;] = popcon[\u0026#39;atime\u0026#39;].astype(int) popcon[\u0026#39;ctime\u0026#39;] = popcon[\u0026#39;ctime\u0026#39;].astype(int) Every numpy array and pandas series has a dtype \u0026ndash; this is usually int64, float64, or object. Some of the time types available are datetime64[s], datetime64[ms], and datetime64[us]. There are also timedelta types, similarly.\nWe can use the pd.to_datetime function to convert our integer timestamps into datetimes. This is a constant-time operation \u0026ndash; we\u0026rsquo;re not actually changing any of the data, just how pandas thinks about it.\npopcon[\u0026#39;atime\u0026#39;] = pd.to_datetime(popcon[\u0026#39;atime\u0026#39;], unit=\u0026#39;s\u0026#39;) popcon[\u0026#39;ctime\u0026#39;] = pd.to_datetime(popcon[\u0026#39;ctime\u0026#39;], unit=\u0026#39;s\u0026#39;) popcon[\u0026#39;atime\u0026#39;].dtype Output:\ndtype(\u0026#39;\u0026lt;M8[ns]\u0026#39;) If we look at the dtype now, it\u0026rsquo;s \u0026lt;M8[ns]. As far as I can tell M8 is secret code for datetime64.\nSo now we can look at our atime and ctime as dates!\npopcon[:5] Output:\nNow suppose we want to look at all packages that aren\u0026rsquo;t libraries.\nFirst, I want to get rid of everything with timestamp 0. Notice how we can just use a string in this comparison, even though it\u0026rsquo;s actually a timestamp on the inside? That is because pandas is amazing.\npopcon = popcon[popcon[\u0026#39;atime\u0026#39;] \u0026gt; \u0026#39;1970-01-01\u0026#39;] Now we can use pandas\u0026rsquo; magical string abilities to just look at rows where the package name doesn\u0026rsquo;t contain \u0026lsquo;lib\u0026rsquo;.\nnonlibraries = popcon[~popcon[\u0026#39;package-name\u0026#39;].str.contains(\u0026#39;lib\u0026#39;)] nonlibraries.sort(\u0026#39;ctime\u0026#39;, ascending=False)[:10] Output:\nOkay, cool, it says that I I installed ddd recently. And postgresql! I remember installing those things. Neat.\nThe whole message here is that if you have a timestamp in seconds or milliseconds or nanoseconds, then you can just \u0026ldquo;cast\u0026rdquo; it to a datetime64[the-right-thing] and pandas/numpy will take care of the rest.\nWhere from here? This was an attempt to provide concise cookbook with real life examples. We suggest you to have a look at the official cookbook also.\n"
},
{
	"uri": "http://tutswiki.com/",
	"title": "TutsWiki Beta",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://tutswiki.com/tags/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://tutswiki.com/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://tutswiki.com/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
}]